Directory Structure:
+ examples
  + javascript
    + advanced-examples
      + multi-agent
        - multi-agent.js
      + pdf-bot-with-stream
        + client
          - client.html
        - README.md
        + server
          - server.js
    - README.md
    - slop.js
  + python
    + advanced-examples
      - multi-agent.py
    - README.md
    - requirements.txt
    - slop.py
  + replit
    - index.html
    - index.js
    - README.md
  + streamlit
    - Makefile
    - README.md
    - requirements.txt
    - slop_with_models.py
    + static
      - openapi.yaml
    - streamlit_slop_with_models.py
    - vars.sh.example
- LICENSE
- README.md
- spec.md

File Contents:
----------------------
EXAMPLES\JAVASCRIPT\ADVANCED-EXAMPLES\MULTI-AGENT\MULTI-AGENT.JS
----------------------
import { OpenAI } from "openai";
import express from "express";
import dotenv from "dotenv";

dotenv.config();

const app = express();
app.use(express.json());
const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });

// Memory storage
const memory = {};

// ======= SIMPLE AGENT SYSTEM =======

// Router Agent - decides which specialized agent to use
async function routerAgent(query) {
  const completion = await openai.chat.completions.create({
    model: "gpt-4",
    messages: [
      { role: "system", content: "You are a router that categorizes queries and selects the best specialized agent to handle them." },
      { role: "user", content: `Classify this query and select ONE agent: "${query}"` }
    ],
    functions: [{
      name: "route_query",
      description: "Route the query to the appropriate agent",
      parameters: {
        type: "object",
        properties: {
          agent: {
            type: "string",
            enum: ["researcher", "creative", "technical", "summarizer"],
            description: "The agent best suited to handle this query"
          },
          reason: {
            type: "string",
            description: "Brief reason for this routing decision"
          }
        },
        required: ["agent", "reason"]
      }
    }],
    function_call: { name: "route_query" }
  });
  
  const args = JSON.parse(completion.choices[0].message.function_call.arguments);
  console.log(`🔀 Routing to: ${args.agent} (${args.reason})`);
  return args;
}

// Create agent factory
const createAgent = (role, temperature = 0.7) => async (query) => {
  const completion = await openai.chat.completions.create({
    model: "gpt-4",
    messages: [
      { role: "system", content: role },
      { role: "user", content: query }
    ],
    temperature
  });
  return completion.choices[0].message.content;
};

// Specialized Agents
const agents = {
  researcher: createAgent("You are a research agent providing factual information with sources.", 0.3),
  creative: createAgent("You are a creative agent generating imaginative content.", 0.9),
  technical: createAgent("You are a technical agent providing precise, detailed explanations.", 0.2),
  summarizer: createAgent("You are a summarization agent that creates concise summaries.", 0.3)
};

// ======= SLOP API IMPLEMENTATION =======

// 1. CHAT endpoint - main entry point
app.post('/chat', async (req, res) => {
  try {
    const { messages, pattern } = req.body;
    const userQuery = messages[0].content;
    let response;

    if (pattern) {
      switch (pattern) {
        case 'sequential':
          // Research → Summarize pattern
          const research = await agents.researcher(userQuery);
          response = await agents.summarizer(research);
          break;

        case 'parallel':
          // Get multiple perspectives simultaneously
          const [researchView, creativeView] = await Promise.all([
            agents.researcher(userQuery),
            agents.creative(userQuery)
          ]);
          response = `Research perspective:\n${researchView}\n\nCreative perspective:\n${creativeView}`;
          break;

        case 'branching':
          // Use router to select best agent
          const route = await routerAgent(userQuery);
          response = await agents[route.agent](userQuery);
          break;

        default:
          // Default to router behavior
          const defaultRoute = await routerAgent(userQuery);
          response = await agents[defaultRoute.agent](userQuery);
      }
    } else {
      // Default to router behavior
      const route = await routerAgent(userQuery);
      response = await agents[route.agent](userQuery);
    }

    // Store in memory
    const sessionId = `session_${Date.now()}`;
    memory[sessionId] = {
      query: userQuery,
      pattern: pattern || 'router',
      response
    };

    res.json({
      message: {
        role: "assistant",
        content: response,
        metadata: {
          session_id: sessionId,
          pattern: pattern || 'router'
        }
      }
    });
  } catch (error) {
    console.error("Error:", error);
    res.status(500).json({ error: error.message });
  }
});

// 2. TOOLS endpoint
app.get('/tools', (req, res) => {
  res.json({
    tools: [
      { id: "researcher", description: "Finds factual information" },
      { id: "creative", description: "Generates imaginative content" },
      { id: "technical", description: "Provides technical explanations" },
      { id: "summarizer", description: "Creates concise summaries" }
    ],
    patterns: [
      { id: "sequential", description: "Research then summarize" },
      { id: "parallel", description: "Multiple perspectives at once" },
      { id: "branching", description: "Route to best agent (default)" }
    ]
  });
});

// 3. MEMORY endpoints
app.post('/memory', (req, res) => {
  const { key, value } = req.body;
  memory[key] = value;
  res.json({ status: 'stored' });
});

app.get('/memory/:key', (req, res) => {
  const { key } = req.params;
  res.json({ value: memory[key] || null });
});

// 4. RESOURCES endpoint
app.get('/resources', (req, res) => {
  res.json({
    patterns: {
      sequential: "Chain agents: Research → Summarize",
      parallel: "Multiple agents work simultaneously",
      branching: "Route to specialized agents"
    },
    examples: {
      sequential: {
        description: "Research a topic and create a summary",
        request: {
          messages: [{ content: "Explain quantum computing" }],
          pattern: "sequential"
        }
      },
      parallel: {
        description: "Get multiple perspectives on a topic",
        request: {
          messages: [{ content: "Benefits of meditation" }],
          pattern: "parallel"
        }
      },
      branching: {
        description: "Route to the most appropriate agent",
        request: {
          messages: [{ content: "How do I write a React component?" }],
          pattern: "branching"
        }
      }
    }
  });
});

// 5. PAY endpoint (simple mock)
app.post('/pay', (req, res) => {
  const { amount } = req.body;
  const txId = `tx_${Date.now()}`;
  memory[txId] = { amount, status: 'completed' };
  res.json({ transaction_id: txId });
});

// Start server
const PORT = process.env.PORT || 3000;
app.listen(PORT, () => {
  console.log(`🤖 SLOP Multi-Agent API running on port ${PORT}`);
});

/* Example usage:

1. Basic query (uses router):
curl -X POST http://localhost:3000/chat \
-H "Content-Type: application/json" \
-d '{
  "messages": [{ "content": "What are black holes?" }]
}'

2. Sequential pattern:
curl -X POST http://localhost:3000/chat \
-H "Content-Type: application/json" \
-d '{
  "messages": [{ "content": "Explain quantum computing" }],
  "pattern": "sequential"
}'

3. Parallel pattern:
curl -X POST http://localhost:3000/chat \
-H "Content-Type: application/json" \
-d '{
  "messages": [{ "content": "Benefits of meditation" }],
  "pattern": "parallel"
}'

4. Store in memory:
curl -X POST http://localhost:3000/memory \
-H "Content-Type: application/json" \
-d '{
  "key": "test",
  "value": "hello world"
}'

5. Get from memory:
curl -X GET http://localhost:3000/memory/test

6. List tools:
curl -X GET http://localhost:3000/tools

7. Get resources:
curl -X GET http://localhost:3000/resources

8. Process payment:
curl -X POST http://localhost:3000/pay \
-H "Content-Type: application/json" \
-d '{
  "amount": 10
}'
*/
----------------------
EXAMPLES\JAVASCRIPT\ADVANCED-EXAMPLES\PDF-BOT-WITH-STREAM\CLIENT\CLIENT.HTML
----------------------
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>SLOP Client</title>
    <!-- Add Showdown library for Markdown to HTML conversion -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/showdown/2.1.0/showdown.min.js"></script>
    
    <!-- Add KaTeX CSS and JS -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css">
    <script src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"></script>

    <link href="https://fonts.googleapis.com/css2?family=League+Spartan:wght@400;500;600;700&display=swap" rel="stylesheet">

    <style>
        * {
            font-family: 'Comic Sans MS', 'Comic Sans', cursive; /* if SLOPPY mode is enabled use comic sans, else league spartan */
        }
        body {
            font-family: 'Comic Sans MS', 'Comic Sans', cursive; /* if SLOPPY mode is enabled use comic sans, else league spartan */
            line-height: 150%;
            background: var(--color-black-navy, #070710);
            color: var(--color-light-med-navy, #d1d1db);
            max-width: 1200px;
            margin: 0 auto;
            padding: 20px;
            height: 100vh;
            -webkit-font-smoothing: antialiased;
            -moz-osx-font-smoothing: grayscale;
        }
        header {
            text-align: center;
            margin-bottom: 30px;
        }
        h1 {
            color: var(--color-blue, #12e0ff);
        }
        .container {
            display: flex;
            flex-direction: column;
            gap: 20px;
            padding-bottom: 24px;
        }
        .upload-panel {
            background-color: var(--color-dark-navy, #10101f);
            padding: 15px;
            border-radius: 8px;
            margin-bottom: 20px;
            box-shadow: 0 4px 6px rgba(0,0,0,0.2);
            border: 1px solid var(--color-navy, #131322);
        }
        .upload-form {
            display: flex;
            flex-direction: column;
            gap: 10px;
        }
        .upload-form-row {
            display: flex;
            align-items: center;
            gap: 10px;
        }
        .upload-btn {
            background-color: var(--color-pink, #e53d8f);
            color: var(--color-white, #f7f8f0);
            border: none;
            padding: 8px 15px;
            border-radius: 4px;
            cursor: pointer;
            transition: all 0.3s ease;
        }
        .upload-btn:hover {
            background-color: var(--color-blue, #12e0ff);
            transform: translateY(-1px);
            box-shadow: 0 2px 4px rgba(18, 224, 255, 0.3);
        }
        .file-counter {
            font-size: var(--font-size-sm, 14px);
            color: var(--color-med-navy, #7f8193);
        }
        .upload-status {
            margin-top: 10px;
            font-size: var(--font-size-sm, 14px);
            color: var(--color-light-med-navy, #d1d1db);
        }
        .resources-panel {
            background-color: var(--color-dark-navy, #10101f);
            padding: 15px;
            border-radius: 8px;
            margin-bottom: 20px;
            box-shadow: 0 4px 6px rgba(0,0,0,0.2);
            border: 1px solid var(--color-navy, #131322);
        }
        .resources-list {
            display: flex;
            gap: 10px;
            flex-wrap: wrap;
            margin-bottom: 10px;
        }
        .resource-btn {
            background-color: var(--color-navy, #131322);
            color: var(--color-light-med-navy, #d1d1db);
            border: 1px solid var(--color-duller-navy, #3e405a);
            padding: 8px 15px;
            border-radius: 4px;
            cursor: pointer;
            transition: all 0.3s ease;
            display: flex;
            align-items: center;
            font-size: var(--font-size-sm, 14px);
        }
        .resource-btn:hover {
            background-color: var(--color-blue, #12e0ff);
            color: var(--color-white, #f7f8f0);
            transform: translateY(-1px);
            box-shadow: 0 2px 4px rgba(18, 224, 255, 0.3);
        }
        .resource-btn.selected {
            background-color: var(--color-green, #19ef83);
            color: var(--color-dark-navy, #10101f);
            border-color: var(--color-green, #19ef83);
            font-weight: bold;
        }
        .resource-icon {
            margin-right: 5px;
            font-size: 16px;
        }
        .chat-container {
            flex-grow: 1;
            display: flex;
            flex-direction: column;
            border: 1px solid var(--color-navy, #131322);
            border-radius: 8px;
            overflow: hidden;
            background: var(--color-ultra-dark-navy, #0b0b17);
            box-shadow: 0 4px 6px rgba(0,0,0,0.2);
        }
        .messages {
            flex-grow: 1;
            padding: 15px;
            overflow-y: auto;
            max-height: calc(100vh - 300px);
        }
        .message {
            margin-bottom: 15px;
            padding: 10px;
            border-radius: 8px;
            box-shadow: 0 2px 4px rgba(0,0,0,0.2);
        }
        .user-message {
            background-color: var(--color-navy, #131322);
            color: var(--color-light-med-navy, #d1d1db);
            align-self: flex-end;
            margin-left: 20%;
            border: 1px solid var(--color-blue, #12e0ff);
            border-radius: 16px 16px 4px 16px;
        }
        .assistant-message {
            background-color: var(--color-dark-navy, #10101f);
            color: var(--color-light-med-navy, #d1d1db);
            align-self: flex-start;
            margin-right: 20%;
            border: 1px solid var(--color-duller-navy, #3e405a);
            border-radius: 16px 16px 16px 4px;
        }
        .message pre {
            background-color: var(--color-black-navy, #070710);
            padding: 10px;
            border-radius: 4px;
            overflow-x: auto;
            border: 1px solid var(--color-navy, #131322);
        }
        .message code {
            font-family: 'Comic Sans MS', 'Comic Sans', cursive; /* if SLOPPY mode is enabled use comic sans, else monospace */
            background-color: var(--color-black-navy, #070710);
            color: var(--color-green, #19ef83);
            padding: 2px 4px;
            border-radius: 3px;
        }
        .input-area {
            display: flex;
            padding: 15px;
            background-color: var(--color-dark-navy, #10101f);
            border-top: 1px solid var(--color-navy, #131322);
            gap: 10px;
        }
        #message-input {
            flex-grow: 1;
            padding: 12px;
            border: 1px solid var(--color-duller-navy, #3e405a);
            border-radius: 4px;
            font-size: var(--font-size-md, 16px);
            transition: all 0.3s ease;
            background-color: var(--color-black-navy, #070710);
            color: var(--color-light-med-navy, #d1d1db);
        }
        #message-input:focus {
            outline: none;
            border-color: var(--color-blue, #12e0ff);
            box-shadow: 0 0 0 2px rgba(18, 224, 255, 0.1);
        }
        #send-btn {
            background-color: var(--color-green, #19ef83);
            color: var(--color-black-navy, #070710);
            border: none;
            padding: 10px 20px;
            border-radius: 4px;
            cursor: pointer;
            transition: all 0.3s ease;
            font-weight: bold;
        }
        #send-btn:hover {
            background-color: var(--color-blue, #12e0ff);
            transform: translateY(-1px);
            box-shadow: 0 2px 4px rgba(18, 224, 255, 0.3);
        }
        .controls-panel {
            display: flex;
            justify-content: space-between;
            align-items: center;
            margin-top: 10px;
        }
        #streaming-toggle {
            display: flex;
            align-items: center;
            font-size: var(--font-size-sm, 14px);
            gap: 5px;
            color: var(--color-light-med-navy, #d1d1db);
        }
        #streaming-toggle input[type="checkbox"] {
            accent-color: var(--color-green, #19ef83);
        }
        .clear-chat-btn {
            background-color: var(--color-red, #fe4e4e);
            color: var(--color-white, #f7f8f0);
            border: none;
            padding: 5px 10px;
            border-radius: 4px;
            font-size: var(--font-size-sm, 14px);
            cursor: pointer;
            transition: all 0.3s ease;
        }
        .clear-chat-btn:hover {
            background-color: var(--color-pink, #e53d8f);
            transform: translateY(-1px);
            box-shadow: 0 2px 4px rgba(229, 61, 143, 0.3);
        }
        .cursor {
            display: inline-block;
            width: 8px;
            height: 16px;
            background-color: var(--color-blue, #12e0ff);
            animation: blink 1s infinite;
            margin-left: 2px;
        }
        @keyframes blink {
            50% { opacity: 0; }
        }
        .loading {
            display: inline-block;
            width: 20px;
            height: 20px;
            border: 3px solid var(--color-navy, #131322);
            border-radius: 50%;
            border-top-color: var(--color-blue, #12e0ff);
            animation: spin 1s ease-in-out infinite;
        }
        @keyframes spin {
            to { transform: rotate(360deg); }
        }
        .katex-display {
            overflow-x: auto;
            overflow-y: hidden;
            padding: 10px 0;
            color: var(--color-light-med-navy, #d1d1db);
        }
        .katex {
            font-size: 1.1em;
        }
        
        /* Style scrollbar for Webkit browsers */
        ::-webkit-scrollbar {
            width: 8px;
            height: 8px;
        }
        ::-webkit-scrollbar-track {
            background: var(--color-black-navy, #070710);
        }
        ::-webkit-scrollbar-thumb {
            background: var(--color-duller-navy, #3e405a);
            border-radius: 4px;
        }
        ::-webkit-scrollbar-thumb:hover {
            background: var(--color-blue, #12e0ff);
        }

        #sloppy-toggle {
            display: flex;
            align-items: center;
            font-size: var(--font-size-sm, 14px);
            gap: 5px;
            color: var(--color-light-med-navy, #d1d1db);
            margin-left: 20px;
        }

        #sloppy-toggle input[type="checkbox"] {
            accent-color: var(--color-pink, #e53d8f);
        }

        /* Add CSS variables for fonts */
        :root {
            --font-primary: 'League Spartan', -apple-system, BlinkMacSystemFont, sans-serif;
            --font-code: monospace;
        }

        :root[data-sloppy="true"] {
            --font-primary: 'Comic Sans MS', 'Comic Sans', cursive;
            --font-code: 'Comic Sans MS', 'Comic Sans', cursive;
        }

        /* Update font-family rules to use variables */
        * {
            font-family: var(--font-primary);
        }

        body {
            font-family: var(--font-primary);
            /* ... rest of body styles ... */
        }

        .message code {
            font-family: var(--font-code);
            /* ... rest of code styles ... */
        }
    </style>
</head>
<body>
    <div class="container">
        <header>
            <h1>SLOP PDF Bot With Streaming 📄</h1>
            <p>Interactive interface for the Simple Language Open Protocol</p>
        </header>

        <div class="upload-panel">
            <h3>Upload Documents</h3>
            <p>Upload PDFs, DOCXs, TXT, MD files, images, and more to chat with their content</p>
            <div class="upload-form">
                <div class="upload-form-row">
                    <input type="file" id="file-input" multiple accept=".pdf,.txt,.md,.docx,.csv,.html,.js,.png,.jpg,.jpeg,.gif,.webp" />
                    <span id="file-counter" class="file-counter">No files selected</span>
                    <button id="upload-btn" class="upload-btn">Upload</button>
                </div>
                <div id="upload-status" class="upload-status"></div>
            </div>
        </div>

        <div class="resources-panel">
            <h3>Available Resources</h3>
            <div class="resources-list" id="resources-list">
                <div class="loading"></div>
            </div>
            <div class="controls-panel">
                <div id="streaming-toggle">
                    <input type="checkbox" id="use-streaming" checked>
                    <label for="use-streaming">Use streaming responses</label>
                </div>
                <div id="sloppy-toggle">
                    <input type="checkbox" id="use-sloppy">
                    <label for="use-sloppy">SLOPPY Mode</label>
                </div>
                <button id="clear-chat-btn" class="clear-chat-btn">Clear Chat</button>
            </div>
        </div>

        <div class="chat-container">
            <div class="messages" id="messages">
                <div class="message assistant-message">
                    <p>Hello! I'm your SLOP assistant. How can I help you today? Upload documents and I can answer questions about them!</p>
                </div>
            </div>
            <div class="input-area">
                <input type="text" id="message-input" placeholder="Type your message here...">
                <button id="send-btn">Send</button>
            </div>
        </div>
    </div>

    <script>
        // Initialize Showdown converter for Markdown to HTML
        const converter = new showdown.Converter({
            tables: true,
            simplifiedAutoLink: true,
            strikethrough: true,
            tasklists: true,
            ghCodeBlocks: true,
            // Add custom LaTeX delimiter handling
            extensions: [{
                type: 'lang',
                regex: /\\\((.*?)\\\)/g,
                replace: (_, match) => `<span class="inline-latex">${match}</span>`
            }, {
                type: 'lang',
                regex: /\\\[(.*?)\\\]/g,
                replace: (_, match) => `<div class="display-latex">${match}</div>`
            }]
        });

        // Add function to render LaTeX in an element
        function renderLatex(element) {
            // Find all LaTeX elements
            const inlineElements = element.getElementsByClassName('inline-latex');
            const displayElements = element.getElementsByClassName('display-latex');
            
            // Render inline LaTeX
            Array.from(inlineElements).forEach(el => {
                try {
                    katex.render(el.textContent, el, {
                        displayMode: false,
                        throwOnError: false
                    });
                } catch (error) {
                    console.error('LaTeX rendering error:', error);
                    el.textContent = `[LaTeX Error: ${error.message}]`;
                }
            });
            
            // Render display LaTeX
            Array.from(displayElements).forEach(el => {
                try {
                    katex.render(el.textContent, el, {
                        displayMode: true,
                        throwOnError: false
                    });
                } catch (error) {
                    console.error('LaTeX rendering error:', error);
                    el.textContent = `[LaTeX Error: ${error.message}]`;
                }
            });
        }

        // Base URL for API
        const API_BASE_URL = 'http://localhost:3000';
        let serverConnected = false;

        // Track currently selected resource
        let selectedResourceId = null;
        
        // Show connection status
        const checkServerConnection = async () => {
            try {
                const response = await fetch(`${API_BASE_URL}/resources`, { method: 'GET' });
                if (response.ok) {
                    serverConnected = true;
                    document.querySelector('header p').textContent = 'Connected to SLOP server';
                    document.querySelector('header p').style.color = 'green';
                    return true;
                }
                return false;
            } catch (error) {
                serverConnected = false;
                document.querySelector('header p').textContent = 'Server disconnected - please start the server';
                document.querySelector('header p').style.color = 'red';
                return false;
            }
        };
        
        // Get file icon based on MIME type
        const getFileIcon = (fileType) => {
            if (!fileType) return '📄';
            
            if (fileType.startsWith('image/')) return '🖼️';
            
            switch (fileType) {
                case 'application/pdf':
                    return '📕';
                case 'application/vnd.openxmlformats-officedocument.wordprocessingml.document':
                    return '📝';
                case 'text/plain':
                    return '📄';
                case 'text/markdown':
                    return '📑';
                case 'text/csv':
                    return '📊';
                case 'text/html':
                    return '🌐';
                case 'text/javascript':
                    return '📜';
                default:
                    return '📄';
            }
        };
        
        // Handle file input change
        const fileInput = document.getElementById('file-input');
        const fileCounter = document.getElementById('file-counter');
        
        fileInput.addEventListener('change', () => {
            const fileCount = fileInput.files.length;
            if (fileCount === 0) {
                fileCounter.textContent = 'No files selected';
            } else if (fileCount === 1) {
                fileCounter.textContent = '1 file selected';
            } else {
                fileCounter.textContent = `${fileCount} files selected`;
            }
        });
        
        // Handle file upload
        const uploadBtn = document.getElementById('upload-btn');
        const uploadStatus = document.getElementById('upload-status');
        
        uploadBtn.addEventListener('click', async () => {
            if (!serverConnected) {
                await checkServerConnection();
                if (!serverConnected) {
                    alert('Cannot upload: Server is not connected. Please start the server.');
                    return;
                }
            }
            
            const files = fileInput.files;
            if (files.length === 0) {
                uploadStatus.textContent = 'Please select at least one file to upload.';
                uploadStatus.style.color = 'red';
                return;
            }
            
            // Show loading state
            uploadStatus.textContent = `Uploading ${files.length} file(s)...`;
            uploadStatus.style.color = 'blue';
            
            const formData = new FormData();
            for (const file of files) {
                formData.append('files', file);
            }
            
            try {
                const response = await fetch(`${API_BASE_URL}/resources/upload`, {
                    method: 'POST',
                    body: formData
                });
                
                const data = await response.json();
                
                if (response.ok) {
                    uploadStatus.textContent = `Successfully uploaded ${data.resources.length} file(s)`;
                    uploadStatus.style.color = 'green';
                    
                    // Clear file input
                    fileInput.value = '';
                    fileCounter.textContent = 'No files selected';
                    
                    // Refresh resources list
                    await loadResources();
                    
                    // Select the first resource if available
                    if (data.resources.length > 0) {
                        selectedResourceId = data.resources[0].id;
                        
                        // Add a system message about the upload
                        const messageElement = document.createElement('div');
                        messageElement.classList.add('message', 'assistant-message');
                        
                        if (data.resources.length === 1) {
                            messageElement.innerHTML = `<p>I've loaded <strong>${data.resources[0].title}</strong>. You can now ask me questions about it!</p>`;
                        } else {
                            const fileNames = data.resources.map(r => r.title).join(', ');
                            messageElement.innerHTML = `<p>I've loaded ${data.resources.length} files: <strong>${fileNames}</strong>. The first file is selected. You can now ask me questions about it!</p>`;
                        }
                        
                        document.getElementById('messages').appendChild(messageElement);
                        document.getElementById('messages').scrollTop = document.getElementById('messages').scrollHeight;
                    }
                } else {
                    uploadStatus.textContent = `Error: ${data.error || 'Unknown error'}`;
                    uploadStatus.style.color = 'red';
                }
            } catch (error) {
                console.error('Error uploading files:', error);
                uploadStatus.textContent = 'Error uploading files. Please try again.';
                uploadStatus.style.color = 'red';
            }
        });
        
        // Function to load resources
        const loadResources = async () => {
            if (!await checkServerConnection()) {
                document.getElementById('resources-list').innerHTML = '<p>Server not connected</p>';
                return;
            }
            
            try {
                const response = await fetch(`${API_BASE_URL}/resources`);
                const data = await response.json();
                
                // Display resources as clickable buttons
                const resourcesList = document.getElementById('resources-list');
                resourcesList.innerHTML = '';
                
                data.resources.forEach(resource => {
                    const button = document.createElement('button');
                    button.classList.add('resource-btn');
                    
                    // Add icon based on file type
                    const icon = document.createElement('span');
                    icon.classList.add('resource-icon');
                    icon.textContent = getFileIcon(resource.fileType);
                    button.appendChild(icon);
                    
                    // Add resource title
                    const titleSpan = document.createElement('span');
                    titleSpan.textContent = resource.title;
                    button.appendChild(titleSpan);
                    
                    button.dataset.id = resource.id;
                    
                    // If this is the currently selected resource, mark it as selected
                    if (selectedResourceId === resource.id) {
                        button.classList.add('selected');
                    }
                    
                    button.addEventListener('click', () => {
                        // Toggle selection
                        if (selectedResourceId === resource.id) {
                            selectedResourceId = null;
                            button.classList.remove('selected');
                        } else {
                            // Deselect any previously selected button
                            document.querySelectorAll('.resource-btn.selected').forEach(btn => {
                                btn.classList.remove('selected');
                            });
                            
                            selectedResourceId = resource.id;
                            button.classList.add('selected');
                            
                            // Add a message indicating the selection
                            const messageElement = document.createElement('div');
                            messageElement.classList.add('message', 'assistant-message');
                            messageElement.innerHTML = `<p>You've selected <strong>${resource.title}</strong>. What would you like to know about it?</p>`;
                            document.getElementById('messages').appendChild(messageElement);
                            
                            // Scroll to bottom
                            document.getElementById('messages').scrollTop = document.getElementById('messages').scrollHeight;
                        }
                    });
                    
                    resourcesList.appendChild(button);
                });
                
                if (data.resources.length === 0) {
                    resourcesList.innerHTML = '<p>No resources available</p>';
                }
            } catch (error) {
                console.error('Error fetching resources:', error);
                document.getElementById('resources-list').innerHTML = '<p>Error loading resources</p>';
            }
        };
        
        // Handle clear chat button
        const clearChatBtn = document.getElementById('clear-chat-btn');
        clearChatBtn.addEventListener('click', () => {
            // Clear all messages except the welcome message
            const messagesContainer = document.getElementById('messages');
            messagesContainer.innerHTML = '';
            
            // Add welcome message
            const welcomeMessage = document.createElement('div');
            welcomeMessage.classList.add('message', 'assistant-message');
            welcomeMessage.innerHTML = '<p>Chat history cleared. How can I help you today?</p>';
            messagesContainer.appendChild(welcomeMessage);
        });
        
        // Fetch available resources when page loads
        document.addEventListener('DOMContentLoaded', loadResources);
        
        // Set up message sending
        const messageInput = document.getElementById('message-input');
        const sendButton = document.getElementById('send-btn');
        const messagesContainer = document.getElementById('messages');
        const streamingToggle = document.getElementById('use-streaming');
        
        const sendMessage = async () => {
            if (!serverConnected) {
                await checkServerConnection();
                if (!serverConnected) {
                    alert('Cannot send message: Server is not connected. Please start the server.');
                    return;
                }
            }

            const messageContent = messageInput.value.trim();
            if (!messageContent) return;
            
            // Add user message to UI
            const userMessageElement = document.createElement('div');
            userMessageElement.classList.add('message', 'user-message');
            userMessageElement.innerHTML = `<p>${messageContent}</p>`;
            messagesContainer.appendChild(userMessageElement);
            
            // Clear input
            messageInput.value = '';
            
            // Add loading indicator for assistant response
            const loadingElement = document.createElement('div');
            loadingElement.classList.add('message', 'assistant-message');
            loadingElement.innerHTML = '<div class="loading"></div>';
            messagesContainer.appendChild(loadingElement);
            
            // Scroll to bottom
            messagesContainer.scrollTop = messagesContainer.scrollHeight;
            
            // Check if streaming is enabled
            const useStreaming = streamingToggle.checked;
            
            if (useStreaming) {
                // Use streaming endpoint
                await streamingChat(messageContent, loadingElement);
            } else {
                // Use regular chat endpoint
                await regularChat(messageContent, loadingElement);
            }
        };
        
        // Regular chat function (non-streaming)
        const regularChat = async (messageContent, loadingElement) => {
            try {
                // Send request to SLOP server
                const payload = {
                    messages: [{ role: 'user', content: messageContent }]
                };
                
                // Include resource_id if a resource is selected
                if (selectedResourceId) {
                    payload.resource_id = selectedResourceId;
                }
                
                const response = await fetch(`${API_BASE_URL}/chat`, {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json'
                    },
                    body: JSON.stringify(payload)
                });
                
                const data = await response.json();
                
                // Convert Markdown to HTML using Showdown
                const htmlContent = converter.makeHtml(data.message.content);
                
                // Update the loading element with the response
                loadingElement.innerHTML = htmlContent;
                
                // Render any LaTeX in the response
                renderLatex(loadingElement);
                
                // Scroll to bottom
                messagesContainer.scrollTop = messagesContainer.scrollHeight;
            } catch (error) {
                console.error('Error sending message:', error);
                loadingElement.innerHTML = '<p>Error: Failed to get a response. Please try again.</p>';
            }
        };
        
        // Streaming chat function
        const streamingChat = async (messageContent, loadingElement) => {
            try {
                // Prepare for streaming response
                loadingElement.innerHTML = '<div class="streaming-response"></div><div class="cursor"></div>';
                const streamingResponseElement = loadingElement.querySelector('.streaming-response');
                
                // Create payload
                const payload = {
                    messages: [{ role: 'user', content: messageContent }]
                };
                
                // Include resource_id if a resource is selected
                if (selectedResourceId) {
                    payload.resource_id = selectedResourceId;
                }
                
                let accumulatedMarkdown = '';

                // Create an AbortController to handle timeouts and manual aborts
                const controller = new AbortController();
                const timeoutId = setTimeout(() => controller.abort(), 30000); // 30-second timeout
                
                // Use fetch with streaming response handling
                try {
                    const response = await fetch(`${API_BASE_URL}/chat/stream`, {
                        method: 'POST',
                        headers: {
                            'Content-Type': 'application/json'
                        },
                        body: JSON.stringify(payload),
                        signal: controller.signal
                    });
                    
                    // Clear the timeout since we got a response
                    clearTimeout(timeoutId);
                    
                    // Check for successful response
                    if (!response.ok) {
                        throw new Error(`Server returned ${response.status}: ${response.statusText}`);
                    }
                    
                    // Set up reader for the response stream
                    const reader = response.body.getReader();
                    const decoder = new TextDecoder('utf-8');
                    
                    // Define a function to process the data chunks
                    const processStream = async () => {
                        while (true) {
                            const { done, value } = await reader.read();
                            
                            if (done) {
                                // Remove cursor when we're done
                                const cursor = loadingElement.querySelector('.cursor');
                                if (cursor) cursor.remove();
                                break;
                            }
                            
                            // Decode the chunk
                            const chunk = decoder.decode(value, { stream: true });
                            
                            // Process the SSE data format (data: {...}\n\n)
                            const lines = chunk.split('\n\n');
                            
                            for (const line of lines) {
                                if (line.trim() === '') continue;
                                
                                // Extract JSON from the line (remove 'data: ' prefix)
                                const jsonStr = line.replace(/^data: /, '').trim();
                                if (!jsonStr) continue;
                                
                                try {
                                    const data = JSON.parse(jsonStr);
                                    
                                    switch (data.event) {
                                        case 'start':
                                            console.log('Streaming started');
                                            break;
                                            
                                        case 'content':
                                            // Append new content
                                            accumulatedMarkdown += data.content;
                                            // Convert to HTML and update the UI
                                            const htmlContent = converter.makeHtml(accumulatedMarkdown);
                                            streamingResponseElement.innerHTML = htmlContent;
                                            // Render any LaTeX in the response
                                            renderLatex(streamingResponseElement);
                                            // Scroll to bottom
                                            messagesContainer.scrollTop = messagesContainer.scrollHeight;
                                            break;
                                            
                                        case 'end':
                                            console.log('Streaming ended');
                                            // Remove cursor now that we're done
                                            const cursor = loadingElement.querySelector('.cursor');
                                            if (cursor) cursor.remove();
                                            break;
                                            
                                        case 'error':
                                            console.error('Streaming error:', data.error);
                                            loadingElement.innerHTML = `<p>Error: ${data.error}</p>`;
                                            return;
                                    }
                                } catch (err) {
                                    console.error('Error parsing SSE data:', err, jsonStr);
                                }
                            }
                        }
                    };
                    
                    // Start processing the stream
                    await processStream();
                    
                } catch (fetchError) {
                    console.error('Fetch error:', fetchError);
                    loadingElement.innerHTML = `<p>Error: ${fetchError.message}</p>`;
                    
                    // Clean up the timeout if needed
                    clearTimeout(timeoutId);
                }
                
            } catch (error) {
                console.error('Error in streaming chat:', error);
                loadingElement.innerHTML = '<p>Error: Failed to start streaming. Please try again.</p>';
            }
        };
        
        // Handle send button click
        sendButton.addEventListener('click', sendMessage);
        
        // Handle Enter key press
        messageInput.addEventListener('keypress', (e) => {
            if (e.key === 'Enter') {
                sendMessage();
            }
        });

        // Handle SLOPPY Mode toggle
        const sloppyToggle = document.getElementById('use-sloppy');
        sloppyToggle.addEventListener('change', (e) => {
            document.documentElement.setAttribute('data-sloppy', e.target.checked);
            
            // Add a fun message when toggling
            const messageElement = document.createElement('div');
            messageElement.classList.add('message', 'assistant-message');
            if (e.target.checked) {
                messageElement.innerHTML = "<p>🎨 SLOPPY Mode activated! Everything is more fun in Comic Sans!</p>";
            } else {
                messageElement.innerHTML = "<p>🎯 Back to professional mode with League Spartan.</p>";
            }
            messagesContainer.appendChild(messageElement);
            messagesContainer.scrollTop = messagesContainer.scrollHeight;
        });
    </script>
</body>
</html>
----------------------
EXAMPLES\JAVASCRIPT\ADVANCED-EXAMPLES\PDF-BOT-WITH-STREAM\README.MD
----------------------
# 🚀 SLOP: Advanced Streaming AI Chat Platform
> A sophisticated, resource-aware AI chat interface with dynamic memory management and intelligent document handling

![License](https://img.shields.io/badge/license-MIT-blue.svg)
![OpenAI](https://img.shields.io/badge/AI-OpenAI%20GPT-brightgreen)
![Streaming](https://img.shields.io/badge/Streaming-SSE-orange)
![Memory](https://img.shields.io/badge/Memory-Dynamic-purple)

<div align="center">
  <img src="https://github.com/agnt-gg/slop/blob/main/examples/javascript/advanced-examples/pdf-bot-with-stream/screenshot.PNG?raw=true" alt="SLOP PDF Bot Interface" width="100%"/>
  <p><em>SLOP PDF Bot with Dynamic Resource Management and Real-time Streaming</em></p>
</div>

## 🛠️ Quick Installation

### Prerequisites
- Node.js >= 16.0.0
- NPM or Yarn
- OpenAI API key

### Installation Steps

1. **Clone and Install Dependencies**
```bash
# Clone the repository (or download)
git clone https://github.com/agnt-gg/slop
cd examples/javascript/pdf-bot-with-stream

# Install server dependencies
cd server
npm install

# Optional: If you need DOCX support
npm install mammoth

# Create environment file
echo "OPENAI_API_KEY=your_api_key_here" > .env
```

2. **Start the Server**
```bash
npm start
# Server will start on http://localhost:3000
```

3. **Access the Client**
- Open your browser to `http://localhost:3000/client`
- Or serve the client folder separately using any static file server

### Dependencies Overview

#### Server Dependencies
```json
{
  "dependencies": {
    "crypto-js": "^4.2.0",
    "dotenv": "^16.4.7",
    "express": "^4.18.2",
    "multer": "^1.4.5-lts.1",
    "openai": "^4.86.2",
    "pdfreader": "^3.0.7"
  },
  "optionalDependencies": {
    "mammoth": "^1.9.0"
  }
}
```

#### Client Dependencies (CDN)
- Showdown (Markdown parsing)
- KaTeX (LaTeX rendering)
- League Spartan font

### Environment Variables
```env
OPENAI_API_KEY=your_api_key_here
PORT=3000 # Optional, defaults to 3000
```

### Docker Support (Optional)
```bash
# Build the image
docker build -t slop-pdf-bot .

# Run the container
docker run -p 3000:3000 -e OPENAI_API_KEY=your_key_here slop-pdf-bot
```

---

## ✨ SLOP Bot Features

- Modern User Interface
- SLOP Schema Compatible
- Real-time Streaming
- Rich Markdown Support
- LaTeX Math Integration
- Dynamic File Management
- Chat Interface
- Controls & Settings

---

## 🔧 Configuration

### Server Configuration
- Maximum file size: 50MB
- Cache size: 100 items
- Cache cleanup interval: 1 hour
- Supported file types: PDF, DOCX, TXT, MD, CSV, HTML, JS, Images

### Client Configuration
- Streaming toggle
- Resource selection
- Chat history management
- LaTeX rendering options

## 🌟 Key Endpoints

- `/chat` - Main chat endpoint
- `/chat/stream` - Streaming chat endpoint
- `/resources` - Resource management
- `/resources/upload` - File upload endpoint
- `/memory` - Conversation memory management
- `/tools` - Tool integration (extensible)
- `/pay` - Payment integration (placeholder)

## 💡 Usage Examples

### Upload and Query Documents
```javascript
// Upload a PDF
const formData = new FormData();
formData.append('files', pdfFile);
await fetch('/resources/upload', { method: 'POST', body: formData });

// Chat about the document
const response = await fetch('/chat', {
  method: 'POST',
  body: JSON.stringify({
    messages: [{ role: 'user', content: 'Summarize the PDF' }],
    resource_id: 'resource_123'
  })
});
```

### LaTeX Math Support
```markdown
Inline math: \(E = mc^2\)
Display math: \[\sum_{n=1}^{\infty} \frac{1}{n^2} = \frac{\pi^2}{6}\]
```

## 🤝 Contributing

Pull requests are welcome! For major changes, please open an issue first to discuss what you would like to change.

## 📜 License

MIT License - feel free to use this in your own projects!

## 🙏 Acknowledgments

- OpenAI for the GPT API
- KaTeX for LaTeX rendering
- Showdown for Markdown processing
- Express.js team
- PDF and DOCX processing libraries

---

## 🌐 API Endpoints

### Chat Endpoints

#### POST `/chat`
Regular chat endpoint for non-streaming responses.

```javascript
// Request
{
  "messages": [{ "role": "user", "content": "Analyze this document" }],
  "resource_id": "resource_123",  // Optional
  "use_tools": true,             // Optional
  "conversation_id": "conv_456"   // Optional
}

// Response
{
  "message": {
    "role": "assistant",
    "content": "Analysis response..."
  },
  "available_resources": ["resource_123", "resource_456"],
  "tools_available": true,
  "conversation_id": "conv_456",
  "message_count": 5
}
```

#### POST `/chat/stream`
Streaming chat endpoint using Server-Sent Events (SSE).

```javascript
// Request (same format as /chat)
{
  "messages": [{ "role": "user", "content": "Analyze this document" }],
  "resource_id": "resource_123",
  "use_tools": true,
  "conversation_id": "conv_456"
}

// SSE Response Events
data: {"event": "start"}
data: {"event": "content", "content": "Analysis"}
data: {"event": "content", "content": " in progress..."}
data: {"event": "end", "conversation_id": "conv_456", "message_count": 6}
```

### Resource Management

#### GET `/resources`
List all available resources.

```javascript
// Response
{
  "resources": [
    {
      "id": "resource_123",
      "title": "Annual Report.pdf",
      "fileType": "application/pdf",
      "fileSize": 1048576,
      "uploadedAt": "2024-03-15T12:00:00Z"
    }
  ]
}
```

#### GET `/resources/:id`
Get specific resource details.

```javascript
// Response
{
  "id": "resource_123",
  "title": "Annual Report.pdf",
  "content": "Document content...",
  "fileType": "application/pdf",
  "fileSize": 1048576,
  "uploadedAt": "2024-03-15T12:00:00Z"
}
```

#### POST `/resources/upload`
Upload multiple files (up to 5 files, 50MB each).

```javascript
// Multipart form data
files: [File1, File2, ...]

// Response
{
  "success": true,
  "resources": [
    {
      "id": "resource_789",
      "title": "New Document.pdf",
      "fileType": "application/pdf",
      "fileSize": 1048576,
      "uploadedAt": "2024-03-15T12:00:00Z"
    }
  ],
  "message": "2 file(s) uploaded and resources created successfully"
}
```

### Memory Management

#### POST `/memory`
Manage conversation memory.

```javascript
// Request - Clear memory
{
  "conversation_id": "conv_456",
  "operation": "clear"
}

// Request - Get memory
{
  "conversation_id": "conv_456",
  "operation": "get"
}

// Response
{
  "status": "cleared",
  "conversation_id": "conv_456"
}
```

#### GET `/debug/conversations/:id?`
Debug endpoint for conversation inspection.

```javascript
// Response (specific conversation)
{
  "conversation_id": "conv_456",
  "messages": [
    { "role": "user", "content": "Hello" },
    { "role": "assistant", "content": "Hi there!" }
  ]
}

// Response (all conversations)
{
  "conversation_count": 2,
  "conversation_ids": ["conv_456", "conv_789"]
}
```

## 💡 Usage Examples

### Complete Chat Flow

```javascript
// 1. Upload documents
const formData = new FormData();
formData.append('files', pdfFile);
formData.append('files', docxFile);

const uploadResponse = await fetch('/resources/upload', {
  method: 'POST',
  body: formData
});
const { resources } = await uploadResponse.json();

// 2. Regular chat about documents
const chatResponse = await fetch('/chat', {
  method: 'POST',
  headers: { 'Content-Type': 'application/json' },
  body: JSON.stringify({
    messages: [{ 
      role: 'user', 
      content: 'Compare these documents and summarize key differences' 
    }],
    resource_id: resources[0].id
  })
});
const { message } = await chatResponse.json();
```

### Streaming Chat with Error Handling

```javascript
const streamChat = async (message) => {
  const response = await fetch('/chat/stream', {
    method: 'POST',
    headers: { 'Content-Type': 'application/json' },
    body: JSON.stringify({
      messages: [{ role: 'user', content: message }],
      use_tools: true
    })
  });

  const reader = response.body.getReader();
  const decoder = new TextDecoder();

  try {
    while (true) {
      const { done, value } = await reader.read();
      if (done) break;
      
      const chunk = decoder.decode(value);
      const events = chunk.split('\n\n');
      
      for (const event of events) {
        if (!event.trim()) continue;
        const data = JSON.parse(event.replace('data: ', ''));
        
        switch (data.event) {
          case 'start':
            console.log('Stream started');
            break;
          case 'content':
            updateUI(data.content);
            break;
          case 'end':
            console.log('Stream ended');
            break;
          case 'error':
            handleError(data.error);
            break;
        }
      }
    }
  } catch (error) {
    console.error('Stream error:', error);
  }
};
```

### Resource Management

```javascript
// List all resources
const resources = await fetch('/resources').then(r => r.json());

// Get specific resource
const resource = await fetch('/resources/resource_123').then(r => r.json());

// Clear conversation memory
await fetch('/memory', {
  method: 'POST',
  headers: { 'Content-Type': 'application/json' },
  body: JSON.stringify({
    conversation_id: 'conv_456',
    operation: 'clear'
  })
});
```

### Advanced File Upload with Progress

```javascript
const uploadWithProgress = async (files) => {
  const formData = new FormData();
  Array.from(files).forEach(file => {
    formData.append('files', file);
  });

  const xhr = new XMLHttpRequest();
  xhr.upload.onprogress = (event) => {
    const percent = (event.loaded / event.total) * 100;
    updateProgressBar(percent);
  };

  return new Promise((resolve, reject) => {
    xhr.onload = () => resolve(JSON.parse(xhr.response));
    xhr.onerror = () => reject(xhr.statusText);
    xhr.open('POST', '/resources/upload');
    xhr.send(formData);
  });
};
```

## 🔧 Configuration Options

```javascript
// Server configuration
const config = {
  MAX_FILE_SIZE: 50 * 1024 * 1024,  // 50MB
  MAX_FILES: 5,
  CACHE_SIZE: 100,
  CACHE_CLEANUP_INTERVAL: 60 * 60 * 1000,  // 1 hour
  SUPPORTED_MIME_TYPES: [
    'application/pdf',
    'application/vnd.openxmlformats-officedocument.wordprocessingml.document',
    'text/plain',
    'text/markdown',
    'text/csv',
    'text/html',
    'text/javascript',
    'image/jpeg',
    'image/png',
    'image/gif',
    'image/webp'
  ]
};
```

## 🔍 Debugging

```javascript
// Get all conversations
const debug = await fetch('/debug/conversations').then(r => r.json());

// Inspect specific conversation
const conv = await fetch('/debug/conversations/conv_456').then(r => r.json());
```

## 🚨 Error Handling

The API uses standard HTTP status codes:
- 200: Success
- 400: Bad Request
- 401: Unauthorized
- 404: Not Found
- 413: Payload Too Large
- 500: Server Error

Error responses include detailed messages:
```javascript
{
  "error": "File size exceeds maximum limit of 50MB",
  "code": "FILE_TOO_LARGE"
}
```
Built with 🔥 passion and ☕ coffee by SLOPPY developers who love clean code
----------------------
EXAMPLES\JAVASCRIPT\ADVANCED-EXAMPLES\PDF-BOT-WITH-STREAM\SERVER\SERVER.JS
----------------------
import express from 'express';
import dotenv from 'dotenv';
import OpenAI from 'openai';
import fs from 'fs';
import path from 'path';
import multer from 'multer';
import { fileURLToPath } from 'url';
import crypto from 'crypto';
import mammoth from 'mammoth';
import { PdfReader } from 'pdfreader';

// Get current directory
const __filename = fileURLToPath(import.meta.url);
const __dirname = path.dirname(__filename);

dotenv.config();

const app = express();
app.use(express.json());

// Simple file content cache
const fileContentCache = {};

// Add these near the top where other cache declarations are
const fileHashCache = new Map(); // Cache for file hashes
const pdfTextCache = new Map();  // Cache for extracted PDF text
const MAX_CACHE_SIZE = 100;      // Maximum number of items to keep in cache

// Configure multer for file uploads
const uploadsDir = path.join(__dirname, 'uploads');
if (!fs.existsSync(uploadsDir)) {
  fs.mkdirSync(uploadsDir, { recursive: true });
}

const storage = multer.diskStorage({
  destination: (req, file, cb) => {
    cb(null, uploadsDir);
  },
  filename: (req, file, cb) => {
    const uniqueSuffix = Date.now() + '-' + Math.round(Math.random() * 1E9);
    const ext = path.extname(file.originalname);
    cb(null, file.fieldname + '-' + uniqueSuffix + ext);
  }
});

const upload = multer({ 
  storage,
  fileFilter: (req, file, cb) => {
    // Accept more file types
    const allowedTypes = [
      'application/pdf', 
      'text/plain', 
      'text/markdown',
      'text/csv',
      'text/html',
      'text/javascript',
      'application/vnd.openxmlformats-officedocument.wordprocessingml.document', // docx
      'application/octet-stream',
      'image/jpeg',
      'image/png',
      'image/gif',
      'image/webp'
    ];
    
    if (allowedTypes.includes(file.mimetype)) {
      cb(null, true);
    } else {
      cb(new Error(`Unsupported file type: ${file.mimetype}`), false);
    }
  },
  limits: {
    fileSize: 50 * 1024 * 1024, // 50MB max file size
  }
});

// Helper to compute file hash for caching
function computeFileHash(buffer) {
  return crypto.createHash('md5').update(buffer).digest('hex');
}

// Helper to trim text to a word limit
function trimToWordLimit(text, wordLimit) {
  const words = text.split(/\s+/);
  if (words.length <= wordLimit) return text;
  return words.slice(0, wordLimit).join(' ') + '... [Content truncated due to length]';
}

// Add this function to manage cache size
function trimCache(cache) {
  if (cache.size > MAX_CACHE_SIZE) {
    const keysIterator = cache.keys();
    const deleteCount = cache.size - MAX_CACHE_SIZE;
    for (let i = 0; i < deleteCount; i++) {
      cache.delete(keysIterator.next().value);
    }
  }
}

// Update the extractTextFromFile function
async function extractTextFromFile(file) {
  const { originalname, path: filePath, mimetype, size } = file;
  const fileBuffer = fs.readFileSync(filePath);
  
  // Generate hash once and cache it
  let fileHash = fileHashCache.get(filePath);
  if (!fileHash) {
    fileHash = computeFileHash(fileBuffer);
    fileHashCache.set(filePath, fileHash);
    trimCache(fileHashCache);
  }
  
  // Check PDF cache first
  if (pdfTextCache.has(fileHash)) {
    console.log(`Using cached PDF content for ${originalname}`);
    return pdfTextCache.get(fileHash);
  }
  
  let extractedText = '';
  
  try {
    if (mimetype.startsWith('image/')) {
      extractedText = `[This is an image file: ${originalname}]`;
    } else {
      switch (mimetype) {
        case 'application/pdf':
          try {
            // First check if we have it in cache
            if (pdfTextCache.has(fileHash)) {
              extractedText = pdfTextCache.get(fileHash);
              console.log(`PDF cache hit for ${originalname}`);
            } else {
              console.log(`PDF cache miss for ${originalname}, extracting text...`);
              extractedText = await getRawTextFromPDFBuffer(fileBuffer);
              
              // Cache the extracted text with size limit (e.g., 1MB)
              if (extractedText.length < 1024 * 1024) {
                pdfTextCache.set(fileHash, extractedText);
                trimCache(pdfTextCache);
                console.log(`Cached PDF content for ${originalname}`);
              }
            }
          } catch (pdfError) {
            console.error(`Error extracting text from PDF ${originalname}:`, pdfError);
            extractedText = `[Error extracting text from PDF: ${originalname}]`;
          }
          break;
          
        case 'application/vnd.openxmlformats-officedocument.wordprocessingml.document':
          try {
            extractedText = await getRawTextFromDocxBuffer(fileBuffer);
          } catch (docxError) {
            console.error(`Error extracting text from DOCX ${originalname}:`, docxError);
            extractedText = `[Error extracting text from DOCX: ${originalname}]`;
          }
          break;
          
        case 'text/plain':
        case 'text/csv':
        case 'text/html':
        case 'text/javascript':
        case 'text/markdown':
        case 'application/octet-stream':
          extractedText = fileBuffer.toString('utf-8');
          break;
          
        default:
          extractedText = `[Unsupported file type: ${mimetype}]`;
      }
    }
    
    return extractedText;
    
  } catch (error) {
    console.error(`Error extracting text from ${originalname}:`, error);
    return `[Error extracting text from file: ${originalname}]`;
  } finally {
    // Clean up the file from disk after processing
    try {
      fs.unlinkSync(filePath);
      console.log(`Cleaned up temporary file: ${filePath}`);
    } catch (cleanupError) {
      console.error(`Error cleaning up file ${filePath}:`, cleanupError);
    }
  }
}

// Add these utility functions right after the imports and before the app setup
async function getRawTextFromPDFBuffer(pdfBuffer) {
  try {
    return new Promise((resolve, reject) => {
      let textContent = '';
      new PdfReader().parseBuffer(pdfBuffer, (err, item) => {
        if (err) {
          reject(err);
        } else if (item && item.text) {
          textContent += item.text + ' ';
        } else if (!item) {
          // End of PDF file
          resolve(textContent);
        }
      });
    });
  } catch (error) {
    console.error('Error reading PDF file:', error);
    throw error;
  }
}

async function getRawTextFromDocxBuffer(docxBuffer) {
  try {
    const result = await mammoth.extractRawText({ buffer: docxBuffer });
    return result.value;
  } catch (error) {
    console.error('Error reading docx file:', error);
    throw error;
  }
}

// Add this function near the top with other utility functions
async function shouldIncludeResource(message, resourceId) {
  if (!resourceId || !resources[resourceId]) return false;
  
  const resourceCheckPrompt = `Given the user's message: "${message}"
and the fact that they have selected a document titled "${resources[resourceId].title}",
determine if the message is likely asking about or referring to the document's content.
Reply with just "true" or "false".

Example "true" cases:
- "What does the document say about X?"
- "Summarize this"
- "Can you explain the part about X?"
- "What's mentioned in the file?"

Example "false" cases:
- "How are you?"
- "What's the weather like?"
- "Tell me a joke"
- General questions not related to documents`;

  try {
    const completion = await openai.chat.completions.create({
      model: "gpt-4o-mini", // You might want to use a smaller/faster model here
      messages: [
        { role: "system", content: "You are a classifier that responds with only 'true' or 'false'." },
        { role: "user", content: resourceCheckPrompt }
      ],
      temperature: 0.1, // Low temperature for more consistent results
      max_tokens: 10
    });

    const response = completion.choices[0]?.message?.content.toLowerCase().trim();
    return response === 'true';
  } catch (error) {
    console.error('Error in resource check:', error);
    return true; // Default to including resource if check fails
  }
}

// Enable CORS for all routes
app.use((req, res, next) => {
  res.header('Access-Control-Allow-Origin', '*');
  res.header('Access-Control-Allow-Headers', 'Origin, X-Requested-With, Content-Type, Accept');
  res.header('Access-Control-Allow-Methods', 'GET, POST, PUT, DELETE, OPTIONS');
  if (req.method === 'OPTIONS') {
    return res.sendStatus(200);
  }
  next();
});

// Setup OpenAI
const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });

// Read slop.txt for resource_1
let slopContent = "This is an example resource doc for SLOP. The SLOP spec defines 5 endpoints: /chat, /tools, /memory, /resources, and /pay.";
try {
  const slopPath = path.join(process.cwd(), 'slop.txt');
  if (fs.existsSync(slopPath)) {
    slopContent = fs.readFileSync(slopPath, 'utf8');
    console.log('Successfully loaded slop.txt content for resource_1');
  } else {
    console.log('slop.txt not found, using default content for resource_1');
  }
} catch (error) {
  console.error('Error reading slop.txt:', error);
}

// Simple in-memory "resources" store
const resources = {
  "resource_1": {
    id: "resource_1",
    title: "Simple SLOP Reference",
    content: slopContent
  }
};

// Simple in-memory conversation store
const conversations = {};
let lastConversationId = null; // Track the most recent conversation

// GET /resources - Return all available resources
app.get('/resources', (req, res) => {
  res.json({ resources: Object.values(resources) });
});

// GET /resources/:id - Return a specific resource
app.get('/resources/:id', (req, res) => {
  const resource = resources[req.params.id];
  if (!resource) {
    return res.status(404).json({ error: 'Resource not found' });
  }
  res.json(resource);
});

// POST /resources/upload - Enhanced file upload with multiple file support
app.post('/resources/upload', upload.array('files', 5), async (req, res) => {
  try {
    if (!req.files || req.files.length === 0) {
      return res.status(400).json({ error: 'No files uploaded' });
    }

    const uploadedResources = [];
    
    // Process each uploaded file
    for (const file of req.files) {
      console.log(`\n\n==== PROCESSING UPLOADED FILE ====`);
      console.log(`File name: ${file.originalname}`);
      console.log(`File type: ${file.mimetype}`);
      console.log(`File size: ${(file.size / 1024).toFixed(2)} KB`);
      
      // Generate a unique resource ID
      const resourceId = `resource_${Date.now()}_${Math.floor(Math.random() * 1000)}`;
      
      // Extract content from the file
      console.log(`Extracting content from file...`);
      const content = await extractTextFromFile(file);
      console.log(`Extracted content length: ${content.length} characters`);
      console.log(`Content preview: ${content.substring(0, 300)}...`);
      
      // Trim content if it's too long
      const trimmedContent = trimToWordLimit(content, 8000); // Limiting to 8000 words
      console.log(`Trimmed content length: ${trimmedContent.length} characters`);
      
      // Create a new resource
      resources[resourceId] = {
        id: resourceId,
        title: file.originalname,
        content: trimmedContent,
        fileType: file.mimetype,
        fileSize: file.size,
        uploadedAt: new Date().toISOString()
      };
      
      console.log(`Created new resource: ${resourceId} from file: ${file.originalname}`);
      console.log(`==== END PROCESSING UPLOADED FILE ====\n\n`);
      
      uploadedResources.push(resources[resourceId]);
    }
    
    res.json({ 
      success: true, 
      resources: uploadedResources,
      message: `${uploadedResources.length} file(s) uploaded and resources created successfully` 
    });
    
  } catch (error) {
    console.error('Error uploading files:', error);
    res.status(500).json({ error: error.message });
  }
});

// POST /chat - Enhanced main endpoint with access to resources, tools and memory
app.post('/chat', async (req, res) => {
  try {
    const { messages, resource_id, use_tools, conversation_id } = req.body;
    
    // Use provided ID, or last conversation ID, or create new one
    const conversationId = conversation_id || lastConversationId || `conv_${Date.now()}`;
    lastConversationId = conversationId; // Update the last used conversation
    
    if (!conversations[conversationId]) {
      conversations[conversationId] = [];
      console.log(`Created new conversation: ${conversationId}`);
    } else {
      console.log(`Using existing conversation: ${conversationId} with ${conversations[conversationId].length} messages`);
    }
    
    // Get existing conversation history
    const conversationHistory = conversations[conversationId];
    
    // Add the new user message to history (only if it's not already there)
    if (messages && messages.length > 0) {
      const latestMessage = messages[messages.length - 1];
      if (latestMessage.role === 'user') {
        // Check if this message is already in the history to avoid duplicates
        const isDuplicate = conversationHistory.some(
          msg => msg.role === 'user' && msg.content === latestMessage.content
        );
        
        if (!isDuplicate) {
          conversationHistory.push(latestMessage);
          console.log(`Added user message to history: ${latestMessage.content}`);
        }
      }
    }

    // Build context with resources - Modified section
    let resourceContext = '';
    let includeResource = false;
    
    if (resource_id && messages && messages.length > 0) {
      // Check if we should include the resource
      includeResource = await shouldIncludeResource(
        messages[messages.length - 1].content,
        resource_id
      );
      
      if (includeResource) {
        resourceContext = `Resource: ${resources[resource_id].title}\n${resources[resource_id].content}\n\n`;
        console.log(`\n\n==== RESOURCE CONTENT BEING SENT TO AI ====`);
        console.log(`Resource ID: ${resource_id}`);
        console.log(`Resource Title: ${resources[resource_id].title}`);
        console.log(`Content Length: ${resources[resource_id].content.length} characters`);
        console.log(`First 500 chars: ${resources[resource_id].content.substring(0, 500)}...`);
        console.log(`==== END RESOURCE CONTENT PREVIEW ====\n\n`);
      } else {
        console.log(`Skipping resource content as query doesn't seem to need it`);
        resourceContext = "Note: You have access to documents but this query doesn't seem to need them.\n";
      }
    } else {
      resourceContext = "Available resources:\n";
      Object.values(resources).forEach(resource => {
        resourceContext += `- ${resource.title} (ID: ${resource.id})\n`;
      });
    }

    // Build system prompt with resources and tool availability
    const systemPrompt = `You are a helpful assistant${includeResource ? ' with access to the following resource:' : ''}.
${resourceContext}
${use_tools ? "You can use tools to help answer the query if needed." : ""}
Answer user queries thoughtfully based on this information.
IMPORTANT: When users ask about things they've previously mentioned in this conversation, 
use that information to provide personalized responses.`;

    console.log(`\n\n==== SYSTEM PROMPT BEING SENT TO AI ====`);
    console.log(systemPrompt.substring(0, 1000) + (systemPrompt.length > 1000 ? '...' : ''));
    console.log(`==== END SYSTEM PROMPT PREVIEW (${systemPrompt.length} characters total) ====\n\n`);

    console.log(`\n\nFull conversation history (${conversationHistory.length} messages):\n\n`, 
      JSON.stringify(conversationHistory));

    // Send to OpenAI with full conversation history
    const completion = await openai.chat.completions.create({
      model: "gpt-4o-mini",
      messages: [
        { role: "system", content: systemPrompt },
        ...conversationHistory
      ],
      temperature: 0.7,
      max_tokens: 4000
    });

    // Get AI response
    const aiResponse = completion.choices[0]?.message?.content || '';
    console.log(`AI response: ${aiResponse}`);
    
    // Format the response for consistency (remove excess whitespace/newlines)
    const formattedResponse = aiResponse.trim();
    
    // Add AI response to conversation history
    conversationHistory.push({ role: "assistant", content: formattedResponse });
    
    // Return AI response with additional context
    res.json({ 
      message: { role: "assistant", content: formattedResponse },
      available_resources: Object.keys(resources),
      tools_available: use_tools,
      conversation_id: conversationId,
      message_count: conversationHistory.length
    });
  } catch (err) {
    console.error("Error in chat endpoint:", err);
    res.status(500).json({ error: err.message });
  }
});

// POST /chat/stream - Streaming version of the chat endpoint
app.post('/chat/stream', async (req, res) => {
  try {
    const { messages, resource_id, use_tools, conversation_id } = req.body;
    
    // Set headers for SSE
    res.setHeader('Content-Type', 'text/event-stream');
    res.setHeader('Cache-Control', 'no-cache');
    res.setHeader('Connection', 'keep-alive');
    res.setHeader('Access-Control-Allow-Origin', '*');
    res.setHeader('X-Accel-Buffering', 'no'); // Important for Nginx
    res.setHeader('Transfer-Encoding', 'chunked');
    
    // Disable response buffering
    res.flushHeaders();
    
    // Use provided ID, or last conversation ID, or create new one
    const conversationId = conversation_id || lastConversationId || `conv_${Date.now()}`;
    lastConversationId = conversationId; // Update the last used conversation
    
    if (!conversations[conversationId]) {
      conversations[conversationId] = [];
      console.log(`Created new conversation: ${conversationId}`);
    } else {
      console.log(`Using existing conversation: ${conversationId} with ${conversations[conversationId].length} messages`);
    }
    
    // Get existing conversation history
    const conversationHistory = conversations[conversationId];
    
    // Add the new user message to history (only if it's not already there)
    if (messages && messages.length > 0) {
      const latestMessage = messages[messages.length - 1];
      if (latestMessage.role === 'user') {
        // Check if this message is already in the history to avoid duplicates
        const isDuplicate = conversationHistory.some(
          msg => msg.role === 'user' && msg.content === latestMessage.content
        );
        
        if (!isDuplicate) {
          conversationHistory.push(latestMessage);
          console.log(`Added user message to history: ${latestMessage.content}`);
        }
      }
    }

    // Build context with resources - Modified section
    let resourceContext = '';
    let includeResource = false;
    
    if (resource_id && messages && messages.length > 0) {
      // Check if we should include the resource
      includeResource = await shouldIncludeResource(
        messages[messages.length - 1].content,
        resource_id
      );
      
      if (includeResource) {
        resourceContext = `Resource: ${resources[resource_id].title}\n${resources[resource_id].content}\n\n`;
        console.log(`\n\n==== RESOURCE CONTENT BEING SENT TO AI (STREAM) ====`);
        console.log(`Resource ID: ${resource_id}`);
        console.log(`Resource Title: ${resources[resource_id].title}`);
        console.log(`Content Length: ${resources[resource_id].content.length} characters`);
        console.log(`First 500 chars: ${resources[resource_id].content.substring(0, 500)}...`);
        console.log(`==== END RESOURCE CONTENT PREVIEW ====\n\n`);
      } else {
        console.log(`Skipping resource content as query doesn't seem to need it`);
        resourceContext = "Note: You have access to documents but this query doesn't seem to need them.\n";
      }
    } else {
      resourceContext = "Available resources:\n";
      Object.values(resources).forEach(resource => {
        resourceContext += `- ${resource.title} (ID: ${resource.id})\n`;
      });
    }

    // Build system prompt with resources and tool availability
    const systemPrompt = `You are a helpful assistant${includeResource ? ' with access to the following resource:' : ''}.
${resourceContext}
${use_tools ? "You can use tools to help answer the query if needed." : ""}
Answer user queries thoughtfully based on this information.
IMPORTANT: When users ask about things they've previously mentioned in this conversation, 
use that information to provide personalized responses.`;

    console.log(`\n\n==== SYSTEM PROMPT BEING SENT TO AI (STREAM) ====`);
    console.log(systemPrompt.substring(0, 1000) + (systemPrompt.length > 1000 ? '...' : ''));
    console.log(`==== END SYSTEM PROMPT PREVIEW (${systemPrompt.length} characters total) ====\n\n`);

    console.log(`\n\nFull conversation history (${conversationHistory.length} messages):\n\n`, 
      JSON.stringify(conversationHistory));

    // Send a message to inform the client we're starting
    res.write(`data: ${JSON.stringify({ event: 'start' })}\n\n`);

    // Create a full response string to store the complete response
    let fullResponse = '';

    try {
      // Stream the response from OpenAI
      const stream = await openai.chat.completions.create({
        model: "gpt-4o-mini",
        messages: [
          { role: "system", content: systemPrompt },
          ...conversationHistory
        ],
        temperature: 0.7,
        stream: true,
        max_tokens: 4000
      });

      // Process each chunk as it arrives
      for await (const chunk of stream) {
        const content = chunk.choices[0]?.delta?.content || '';
        if (content) {
          fullResponse += content;
          // Send each content chunk to the client
          res.write(`data: ${JSON.stringify({ event: 'content', content })}\n\n`);
        }
      }

      // Add the complete response to conversation history
      conversationHistory.push({ role: "assistant", content: fullResponse });
      
    } catch (streamError) {
      console.error("Error streaming from OpenAI:", streamError);
      res.write(`data: ${JSON.stringify({ event: 'error', error: streamError.message })}\n\n`);
    }
    
    // Send a message to inform the client we're done
    res.write(`data: ${JSON.stringify({ 
      event: 'end',
      conversation_id: conversationId,
      message_count: conversationHistory.length
    })}\n\n`);
    
    // End the response
    res.end();
    
  } catch (err) {
    console.error("Error in streaming chat endpoint:", err);
    // Send error to client if we can
    try {
      res.write(`data: ${JSON.stringify({ event: 'error', error: err.message })}\n\n`);
      res.end();
    } catch (e) {
      console.error("Could not send error to client:", e);
    }
  }
});

// Create a separate endpoint to receive stream parameters via GET
app.get('/chat/stream', (req, res) => {
  // Set up SSE headers
  res.setHeader('Content-Type', 'text/event-stream');
  res.setHeader('Cache-Control', 'no-cache');
  res.setHeader('Connection', 'keep-alive');
  res.setHeader('Access-Control-Allow-Origin', '*');
  res.setHeader('X-Accel-Buffering', 'no'); // Important for Nginx
  
  // Send a message to inform the client that a POST request is needed
  res.write(`data: ${JSON.stringify({ 
    event: 'error', 
    error: 'Please use POST /chat/stream with your message and parameters in the body'
  })}\n\n`);
  
  res.end();
});

// Add a debug endpoint to check conversations
app.get('/debug/conversations/:id?', (req, res) => {
  const { id } = req.params;
  
  if (id) {
    // Return specific conversation
    if (conversations[id]) {
      res.json({ conversation_id: id, messages: conversations[id] });
    } else {
      res.status(404).json({ error: "Conversation not found" });
    }
  } else {
    // Return list of all conversation IDs
    res.json({ 
      conversation_count: Object.keys(conversations).length,
      conversation_ids: Object.keys(conversations)
    });
  }
});

// Update memory endpoint to actually do something
app.post('/memory', (req, res) => {
  const { conversation_id, operation } = req.body;
  
  if (operation === 'clear' && conversation_id && conversations[conversation_id]) {
    // Clear specific conversation
    conversations[conversation_id] = [];
    res.json({ status: "cleared", conversation_id });
  } 
  else if (operation === 'get' && conversation_id && conversations[conversation_id]) {
    // Retrieve specific conversation
    res.json({ 
      status: "retrieved", 
      conversation_id,
      messages: conversations[conversation_id]
    });
  }
  else {
    res.json({ status: "no operation performed" });
  }
});

// Minimal endpoints for SLOP compliance:

// POST /tools (dummy)
app.post('/tools', (req, res) => {
  res.json({ result: "Tool used (dummy response)." });
});

// POST /pay (dummy)
app.post('/pay', (req, res) => {
  res.json({ transaction_id: `tx_${Date.now()}`, status: "success" });
});

// Start server
const PORT = process.env.PORT || 3000;
app.listen(PORT, () => {
  console.log(`Simple SLOP chatbot running on port ${PORT}`);
  console.log(`Open your browser to http://localhost:${PORT}/client to access the SLOP client`);
});

// Serve the client
app.get('/client', (req, res) => {
  res.sendFile(process.cwd() + '/../SLOP-CLIENT/index.html');
});

// Add a cleanup function for the caches
function clearOldCaches() {
  const ONE_HOUR = 60 * 60 * 1000;
  setInterval(() => {
    fileHashCache.clear();
    pdfTextCache.clear();
    console.log('Cleared PDF and file hash caches');
  }, ONE_HOUR);
}

// Call this after your app is initialized
clearOldCaches();

----------------------
EXAMPLES\JAVASCRIPT\README.MD
----------------------
# SLOP JavaScript Example

A simple implementation of the [SLOP](https://github.com/agnt-gg/slop) pattern in JavaScript.

## JavaScript Quick Start

```bash
# Clone the repo
git clone https://github.com/agnt-gg/slop
cd slop/javascript

# Install dependencies
npm install

# Run it
npm start
```

## Endpoints

```javascript
// CHAT - Talk to AI
POST /chat
{
  "messages": [{ "content": "Hello SLOP!" }]
}

// TOOLS - Use tools
GET /tools
POST /tools/calculator { "expression": "2 + 2" }
POST /tools/greet { "name": "SLOP" }

// MEMORY - Store data
POST /memory { "key": "test", "value": "hello" }
GET /memory/test

// RESOURCES - Get knowledge
GET /resources
GET /resources/hello

// PAY - Handle payments
POST /pay { "amount": 10 }
```

## Structure

- `slop.js` - The entire implementation
- `package.json` - Dependencies and scripts

That's it. Just two files.

## Dependencies

- `express` - For clean routing
- `axios` - For clean HTTP requests

## Try It

After starting the server, it automatically runs tests for all endpoints. Watch the magic happen!

```bash
npm start

# Output:
✨ SLOP running on http://localhost:3000

📝 Testing chat...
You said: Hello SLOP!

🔧 Testing tools...
2 + 2 = 4
Hello, SLOP!

💾 Testing memory...
Stored value: hello world

📚 Testing resources...
Resource content: Hello, SLOP!

💰 Testing pay...
Transaction: tx_1234567890

✅ All tests passed!
```

## Learn More

Check out the [main SLOP repository](https://github.com/agnt-gg/slop) for:
- Full specification
- Other language examples
- Core concepts
- Best practices

Remember: SLOP is just a pattern. This is a simple implementation example to show how it works.
----------------------
EXAMPLES\JAVASCRIPT\SLOP.JS
----------------------
// JavaScript implementation of the SLOP pattern
import express from 'express';
import axios from 'axios';

// Available tools and resources
const tools = {
  calculator: {
    id: 'calculator',
    description: 'Basic math',
    execute: params => ({ result: eval(params.expression) })
  },
  greet: {
    id: 'greet',
    description: 'Says hello',
    execute: params => ({ result: `Hello, ${params.name}!` })
  }
};

const resources = {
  hello: { id: 'hello', content: 'Hello, SLOP!' }
};

// Setup server
const app = express();
app.use(express.json());

// In-memory storage
const memory = new Map();

// CHAT
app.post('/chat', (req, res) => {
  const message = req.body.messages?.[0]?.content || 'nothing';
  res.json({
    message: {
      role: 'assistant',
      content: `You said: ${message}`
    }
  });
});

// TOOLS
app.get('/tools', (_, res) => res.json({ tools: Object.values(tools) }));
app.post('/tools/:id', (req, res) => {
  const tool = tools[req.params.id];
  if (!tool) return res.status(404).json({ error: 'Tool not found' });
  res.json(tool.execute(req.body));
});

// MEMORY
app.post('/memory', (req, res) => {
  const { key, value } = req.body;
  memory.set(key, value);
  res.json({ status: 'stored' });
});

app.get('/memory/:key', (req, res) => {
  res.json({ value: memory.get(req.params.key) });
});

// RESOURCES
app.get('/resources', (_, res) => res.json({ resources: Object.values(resources) }));
app.get('/resources/:id', (req, res) => {
  const resource = resources[req.params.id];
  if (!resource) return res.status(404).json({ error: 'Resource not found' });
  res.json(resource);
});

// PAY
app.post('/pay', (_, res) => {
  res.json({
    transaction_id: 'tx_' + Date.now(),
    status: 'success'
  });
});

// Start server and run tests
app.listen(3000, async () => {
  console.log('✨ SLOP running on http://localhost:3000\n');
  
  const api = axios.create({ baseURL: 'http://localhost:3000' });
  
  try {
    // Test chat
    console.log('📝 Testing chat...');
    const chat = await api.post('/chat', {
      messages: [{ content: 'Hello SLOP!' }]
    });
    console.log(chat.data.message.content, '\n');

    // Test tools
    console.log('🔧 Testing tools...');
    const calc = await api.post('/tools/calculator', {
      expression: '2 + 2'
    });
    console.log('2 + 2 =', calc.data.result);

    const greet = await api.post('/tools/greet', {
      name: 'SLOP'
    });
    console.log(greet.data.result, '\n');

    // Test memory
    console.log('💾 Testing memory...');
    await api.post('/memory', {
      key: 'test',
      value: 'hello world'
    });
    const memory = await api.get('/memory/test');
    console.log('Stored value:', memory.data.value, '\n');

    // Test resources
    console.log('📚 Testing resources...');
    const hello = await api.get('/resources/hello');
    console.log('Resource content:', hello.data.content, '\n');

    // Test pay
    console.log('💰 Testing pay...');
    const pay = await api.post('/pay', {
      amount: 10
    });
    console.log('Transaction:', pay.data.transaction_id, '\n');

    console.log('✅ All tests passed!');
  } catch (error) {
    console.error('❌ Test failed:', error.response?.data || error.message);
  }
});
----------------------
EXAMPLES\PYTHON\ADVANCED-EXAMPLES\MULTI-AGENT.PY
----------------------
import os
import json
import time
from flask import Flask, request, jsonify
from openai import OpenAI
from dotenv import load_dotenv
from typing import List, Dict, Any
import asyncio

# Load environment variables
load_dotenv()

# Initialize Flask app
app = Flask(__name__)

# Initialize OpenAI client
openai = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# Memory storage
memory = {}

# ======= SIMPLE AGENT SYSTEM =======

# Router Agent - decides which specialized agent to use
def router_agent(query: str) -> Dict[str, str]:
    completion = openai.chat.completions.create(
        model="gpt-4",
        messages=[
            {"role": "system", "content": "You are a router that categorizes queries and selects the best specialized agent to handle them."},
            {"role": "user", "content": f'Classify this query and select ONE agent: "{query}"'}
        ],
        tools=[{
            "type": "function",
            "function": {
                "name": "route_query",
                "description": "Route the query to the appropriate agent",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "agent": {
                            "type": "string",
                            "enum": ["researcher", "creative", "technical", "summarizer"],
                            "description": "The agent best suited to handle this query"
                        },
                        "reason": {
                            "type": "string",
                            "description": "Brief reason for this routing decision"
                        }
                    },
                    "required": ["agent", "reason"]
                }
            }
        }],
        tool_choice={"type": "function", "function": {"name": "route_query"}}
    )
    
    tool_call = completion.choices[0].message.tool_calls[0]
    args = json.loads(tool_call.function.arguments)
    print(f"🔀 Routing to: {args['agent']} ({args['reason']})")
    return args

# Create agent factory
def create_agent(role: str, temperature: float = 0.7):
    async def agent(query: str) -> str:
        completion = await asyncio.to_thread(
            openai.chat.completions.create,
            model="gpt-4",
            messages=[
                {"role": "system", "content": role},
                {"role": "user", "content": query}
            ],
            temperature=temperature
        )
        return completion.choices[0].message.content
    return agent

# Specialized Agents
agents = {
    "researcher": create_agent("You are a research agent providing factual information with sources.", 0.3),
    "creative": create_agent("You are a creative agent generating imaginative content.", 0.9),
    "technical": create_agent("You are a technical agent providing precise, detailed explanations.", 0.2),
    "summarizer": create_agent("You are a summarization agent that creates concise summaries.", 0.3)
}

# ======= SLOP API IMPLEMENTATION =======

# 1. CHAT endpoint - main entry point
@app.route('/chat', methods=['POST'])
async def chat():
    try:
        data = request.json
        messages = data.get('messages', [])
        pattern = data.get('pattern')
        user_query = messages[0]['content'] if messages else ""
        
        response = None

        if pattern:
            if pattern == 'sequential':
                # Research then summarize
                research = await agents["researcher"](user_query)
                response = await agents["summarizer"](research)
            
            elif pattern == 'parallel':
                # Get multiple perspectives simultaneously
                research_task = agents["researcher"](user_query)
                creative_task = agents["creative"](user_query)
                results = await asyncio.gather(research_task, creative_task)
                response = f"Research perspective:\n{results[0]}\n\nCreative perspective:\n{results[1]}"
            
            elif pattern == 'branching':
                route = router_agent(user_query)
                response = await agents[route['agent']](user_query)
            
            else:
                # Default to router behavior
                route = router_agent(user_query)
                response = await agents[route['agent']](user_query)
        else:
            # Default to router behavior
            route = router_agent(user_query)
            response = await agents[route['agent']](user_query)
        
        # Store in memory
        session_id = f"session_{int(time.time())}"
        memory[session_id] = {
            "query": user_query,
            "pattern": pattern or "router",
            "response": response
        }
        
        return jsonify({
            "message": {
                "role": "assistant",
                "content": response,
                "metadata": {
                    "session_id": session_id,
                    "pattern": pattern or "router"
                }
            }
        })
    except Exception as e:
        print(f"Error: {str(e)}")
        return jsonify({"error": str(e)}), 500

# 2. TOOLS endpoint
@app.route('/tools', methods=['GET'])
def list_tools():
    return jsonify({
        "tools": [
            {"id": "researcher", "description": "Finds factual information"},
            {"id": "creative", "description": "Generates imaginative content"},
            {"id": "technical", "description": "Provides technical explanations"},
            {"id": "summarizer", "description": "Creates concise summaries"}
        ],
        "patterns": [
            {"id": "sequential", "description": "Research then summarize"},
            {"id": "parallel", "description": "Multiple perspectives at once"},
            {"id": "branching", "description": "Route to best agent (default)"}
        ]
    })

# 3. MEMORY endpoints
@app.route('/memory', methods=['POST'])
def store_memory():
    data = request.json
    key = data.get('key')
    value = data.get('value')
    memory[key] = value
    return jsonify({"status": "stored"})

@app.route('/memory/<key>', methods=['GET'])
def get_memory(key):
    return jsonify({"value": memory.get(key)})

# 4. RESOURCES endpoint
@app.route('/resources', methods=['GET'])
def get_resources():
    return jsonify({
        "patterns": {
            "sequential": "Chain agents: Research → Summarize",
            "parallel": "Multiple agents work simultaneously",
            "branching": "Route to specialized agents"
        },
        "examples": {
            "sequential": {
                "description": "Research a topic and create a summary",
                "request": {
                    "messages": [{"content": "Explain quantum computing"}],
                    "pattern": "sequential"
                }
            },
            "parallel": {
                "description": "Get multiple perspectives on a topic",
                "request": {
                    "messages": [{"content": "Benefits of meditation"}],
                    "pattern": "parallel"
                }
            },
            "branching": {
                "description": "Route to the most appropriate agent",
                "request": {
                    "messages": [{"content": "How do I write a Python class?"}],
                    "pattern": "branching"
                }
            }
        }
    })

# 5. PAY endpoint (simple mock)
@app.route('/pay', methods=['POST'])
def process_payment():
    data = request.json
    tx_id = f"tx_{int(time.time())}"
    memory[tx_id] = {"amount": data.get('amount'), "status": "completed"}
    return jsonify({"transaction_id": tx_id})

if __name__ == "__main__":
    port = int(os.getenv("PORT", 3000))
    print(f"🤖 SLOP Multi-Agent API running on port {port}")
    app.run(host="0.0.0.0", port=port, debug=True)

"""
Example usage:

1. Basic query (uses router):
curl -X POST http://localhost:3000/chat \
-H "Content-Type: application/json" \
-d '{
    "messages": [{"content": "What are black holes?"}]
}'

2. Sequential pattern:
curl -X POST http://localhost:3000/chat \
-H "Content-Type: application/json" \
-d '{
    "messages": [{"content": "Explain quantum computing"}],
    "pattern": "sequential"
}'

3. Parallel pattern:
curl -X POST http://localhost:3000/chat \
-H "Content-Type: application/json" \
-d '{
    "messages": [{"content": "Benefits of meditation"}],
    "pattern": "parallel"
}'

4. Store in memory:
curl -X POST http://localhost:3000/memory \
-H "Content-Type: application/json" \
-d '{
    "key": "test",
    "value": "hello world"
}'

5. Get from memory:
curl -X GET http://localhost:3000/memory/test

6. List tools:
curl -X GET http://localhost:3000/tools

7. Get resources:
curl -X GET http://localhost:3000/resources

8. Process payment:
curl -X POST http://localhost:3000/pay \
-H "Content-Type: application/json" \
-d '{
    "amount": 10
}'
"""
----------------------
EXAMPLES\PYTHON\README.MD
----------------------
# SLOP Python Example

A simple implementation of the [SLOP](https://github.com/agnt-gg/slop) pattern in Python.

## Python Quick Start

```bash
# Clone the repo
git clone https://github.com/agnt-gg/slop
cd slop/python

# Create virtual environment (optional but recommended)
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Run it
python slop.py
```

## Endpoints

```python
# CHAT - Talk to AI
POST /chat
{
  "messages": [{ "content": "Hello SLOP!" }]
}

# TOOLS - Use tools
GET /tools
POST /tools/calculator { "expression": "2 + 2" }
POST /tools/greet { "name": "SLOP" }

# MEMORY - Store data
POST /memory { "key": "test", "value": "hello" }
GET /memory/test

# RESOURCES - Get knowledge
GET /resources
GET /resources/hello

# PAY - Handle payments
POST /pay { "amount": 10 }
```

## Structure

- `slop.py` - The entire implementation
- `requirements.txt` - Dependencies

That's it. Just two files.

## Dependencies

- `flask` - For clean routing
- `requests` - For testing endpoints

## Try It

After starting the server, it automatically runs tests for all endpoints:

```bash
python slop.py

# Output:
✨ SLOP running on http://localhost:5000
🚀 Running tests...

📝 Testing chat...
You said: Hello SLOP!

🔧 Testing tools...
2 + 2 = 4
Hello, SLOP!

💾 Testing memory...
Stored value: hello world

📚 Testing resources...
Resource content: Hello, SLOP!

💰 Testing pay...
Transaction: tx_1234567890

✅ All tests passed!
```

## Learn More

Check out the [main SLOP repository](https://github.com/agnt-gg/slop) for:
- Full specification
- Other language examples
- Core concepts
- Best practices

Remember: SLOP is just a pattern. This is a simple implementation example to show how it works.
----------------------
EXAMPLES\PYTHON\REQUIREMENTS.TXT
----------------------
flask==3.0.2
requests==2.31.0
----------------------
EXAMPLES\PYTHON\SLOP.PY
----------------------
# Python implementation of the SLOP pattern

from flask import Flask, request, jsonify
import requests
from datetime import datetime

# Initialize Flask app
app = Flask(__name__)

# Available tools and resources
tools = {
    'calculator': {
        'id': 'calculator',
        'description': 'Basic math',
        'execute': lambda params: {'result': eval(params['expression'])}
    },
    'greet': {
        'id': 'greet',
        'description': 'Says hello',
        'execute': lambda params: {'result': f"Hello, {params['name']}!"}
    }
}

resources = {
    'hello': {'id': 'hello', 'content': 'Hello, SLOP!'}
}

# In-memory storage
memory = {}

# CHAT
@app.route('/chat', methods=['POST'])
def chat():
    data = request.json
    message = data.get('messages', [{}])[0].get('content', 'nothing')
    return jsonify({
        'message': {
            'role': 'assistant',
            'content': f'You said: {message}'
        }
    })

# TOOLS
@app.route('/tools', methods=['GET'])
def list_tools():
    return jsonify({'tools': list(tools.values())})

@app.route('/tools/<tool_id>', methods=['POST'])
def use_tool(tool_id):
    if tool_id not in tools:
        return jsonify({'error': 'Tool not found'}), 404
    return jsonify(tools[tool_id]['execute'](request.json))

# MEMORY
@app.route('/memory', methods=['POST'])
def store_memory():
    data = request.json
    memory[data['key']] = data['value']
    return jsonify({'status': 'stored'})

@app.route('/memory/<key>', methods=['GET'])
def get_memory(key):
    return jsonify({'value': memory.get(key)})

# RESOURCES
@app.route('/resources', methods=['GET'])
def list_resources():
    return jsonify({'resources': list(resources.values())})

@app.route('/resources/<resource_id>', methods=['GET'])
def get_resource(resource_id):
    if resource_id not in resources:
        return jsonify({'error': 'Resource not found'}), 404
    return jsonify(resources[resource_id])

# PAY
@app.route('/pay', methods=['POST'])
def pay():
    return jsonify({
        'transaction_id': f'tx_{int(datetime.now().timestamp())}',
        'status': 'success'
    })

def test_endpoints():
    """Test all SLOP endpoints"""
    base = 'http://localhost:5000'
    
    try:
        # Test chat
        print('📝 Testing chat...')
        chat = requests.post(f'{base}/chat', json={
            'messages': [{'content': 'Hello SLOP!'}]
        }).json()
        print(chat['message']['content'], '\n')

        # Test tools
        print('🔧 Testing tools...')
        calc = requests.post(f'{base}/tools/calculator', json={
            'expression': '2 + 2'
        }).json()
        print('2 + 2 =', calc['result'])

        greet = requests.post(f'{base}/tools/greet', json={
            'name': 'SLOP'
        }).json()
        print(greet['result'], '\n')

        # Test memory
        print('💾 Testing memory...')
        requests.post(f'{base}/memory', json={
            'key': 'test',
            'value': 'hello world'
        })
        memory = requests.get(f'{base}/memory/test').json()
        print('Stored value:', memory['value'], '\n')

        # Test resources
        print('📚 Testing resources...')
        hello = requests.get(f'{base}/resources/hello').json()
        print('Resource content:', hello['content'], '\n')

        # Test pay
        print('💰 Testing pay...')
        pay = requests.post(f'{base}/pay', json={
            'amount': 10
        }).json()
        print('Transaction:', pay['transaction_id'], '\n')

        print('✅ All tests passed!')
    except Exception as e:
        print('❌ Test failed:', str(e))

if __name__ == '__main__':
    import threading
    import time
    
    # Start server in a thread
    threading.Thread(target=app.run, daemon=True).start()
    
    # Wait for server to start
    print('✨ SLOP running on http://localhost:5000')
    time.sleep(1)
    print('🚀 Running tests...\n')
    
    # Run tests
    test_endpoints()
----------------------
EXAMPLES\REPLIT\INDEX.HTML
----------------------
<!doctype html>
<html>
  <head>
    <title>My SLOP Chat</title>
    <style>
      body {
        font-family: Arial;
        max-width: 600px;
        margin: 0 auto;
        padding: 20px;
        background-color: #f9f9f9;
      }
      h1 {
        color: #2c3e50;
        text-align: center;
      }
      #chat-container {
        border: 1px solid #ddd;
        border-radius: 8px;
        height: 350px;
        overflow-y: auto;
        padding: 15px;
        margin-bottom: 15px;
        background-color: white;
        box-shadow: 0 2px 5px rgba(0, 0, 0, 0.1);
      }
      #chat-container div {
        margin-bottom: 10px;
        padding: 8px;
        border-radius: 5px;
      }
      #chat-container div:nth-child(odd) {
        background-color: #f1f1f1;
      }
      #user-input {
        width: 75%;
        padding: 10px;
        border: 1px solid #ddd;
        border-radius: 4px;
        font-size: 16px;
      }
      button {
        padding: 10px 20px;
        background: #3498db;
        color: white;
        border: none;
        border-radius: 4px;
        cursor: pointer;
        font-size: 16px;
        transition: background 0.3s;
      }
      button:hover {
        background: #2980b9;
      }
      ul {
        padding-left: 20px;
      }
      li {
        margin: 5px 0;
      }
    </style>
  </head>
  <body>
    <div
      style="
        margin-top: 20px;
        background-color: #e9f7fe;
        padding: 10px;
        border-radius: 5px;
      "
    >
      <p><strong>SLOP Compatibility</strong></p>
      <p>
        This server implements the Simple Language Open Protocol (SLOP) with all
        standard endpoints:
      </p>
      <ul>
        <li><code>POST /chat</code> - Talk to the trivia bot</li>
        <li><code>GET /tools</code> - Get available tools</li>
        <li><code>POST /tools/:tool_id</code> - Use a specific tool</li>
        <li><code>POST /memory</code> - Store key-value data</li>
        <li><code>GET /memory/:key</code> - Retrieve stored data</li>
        <li><code>GET /resources</code> - Get available resources</li>
        <li><code>GET /resources/:id</code> - Get specific resource</li>
        <li><code>POST /pay</code> - Mock payment processing</li>
      </ul>
      <p style="text-align: center; margin-top: 15px">
        <a
          href="/test-slop.html"
          style="
            display: inline-block;
            padding: 10px 20px;
            background: #3498db;
            color: white;
            text-decoration: none;
            border-radius: 4px;
            font-weight: bold;
          "
        >
          Test All SLOP Endpoints
        </a>
      </p>
    </div>
  </body>
</html>

----------------------
EXAMPLES\REPLIT\INDEX.JS
----------------------

const express = require('express');
const app = express();
app.use(express.json());

// Serve static files from the 'public' directory
app.use(express.static('public'));

// Trivia game data
const triviaQuestions = [
  {
    question: "What is the capital of France?",
    answer: "paris",
    hint: "It's known as the City of Light."
  },
  {
    question: "Which planet is known as the Red Planet?",
    answer: "mars",
    hint: "It's named after the Roman god of war."
  },
  {
    question: "What is the largest mammal in the world?",
    answer: "blue whale",
    hint: "It lives in the ocean and can weigh up to 200 tons."
  },
  {
    question: "Who painted the Mona Lisa?",
    answer: "leonardo da vinci",
    hint: "He was an Italian polymath from the Renaissance period."
  },
  {
    question: "What is the chemical symbol for gold?",
    answer: "au",
    hint: "It comes from the Latin word 'aurum'."
  }
];

// Game state
let currentGame = {
  active: false,
  currentQuestion: null,
  score: 0,
  askedQuestions: [],
  hintUsed: false
};

// In-memory storage for SLOP
const memory = new Map();

// 1. CHAT ENDPOINT - SLOP compatible
app.post('/chat', (req, res) => {
  const message = req.body.messages?.[0]?.content || '';
  const lowerMessage = message.toLowerCase();
  
  // Response based on game state and message
  let response = '';

  // Trivia game commands
  if (lowerMessage.includes('start trivia') || lowerMessage.includes('play trivia')) {
    currentGame = {
      active: true,
      currentQuestion: null,
      score: 0,
      askedQuestions: [],
      hintUsed: false
    };
    response = "Welcome to Trivia Challenge! I'll ask you questions and you try to answer them. Say 'next question' to begin!";
  } 
  else if (currentGame.active && (lowerMessage.includes('next question') || lowerMessage.includes('new question'))) {
    // Get a question that hasn't been asked yet
    const availableQuestions = triviaQuestions.filter(q => !currentGame.askedQuestions.includes(q.question));
    
    if (availableQuestions.length === 0) {
      response = `Game over! Your final score is ${currentGame.score}/${triviaQuestions.length}. Say 'start trivia' to play again!`;
      currentGame.active = false;
    } else {
      currentGame.currentQuestion = availableQuestions[Math.floor(Math.random() * availableQuestions.length)];
      currentGame.askedQuestions.push(currentGame.currentQuestion.question);
      currentGame.hintUsed = false;
      response = `Question: ${currentGame.currentQuestion.question} (Say 'hint' if you need help)`;
    }
  }
  else if (currentGame.active && lowerMessage.includes('hint') && currentGame.currentQuestion) {
    currentGame.hintUsed = true;
    response = `Hint: ${currentGame.currentQuestion.hint}`;
  }
  else if (currentGame.active && currentGame.currentQuestion && lowerMessage.includes('skip')) {
    response = `The answer was: ${currentGame.currentQuestion.answer}. Say 'next question' for another one!`;
    currentGame.currentQuestion = null;
  }
  else if (currentGame.active && currentGame.currentQuestion) {
    // Check if the answer is correct
    if (lowerMessage.includes(currentGame.currentQuestion.answer.toLowerCase())) {
      currentGame.score += currentGame.hintUsed ? 0.5 : 1; // Half point if hint was used
      response = currentGame.hintUsed ? 
        `Correct! You get half a point for using a hint. Your score is now ${currentGame.score}. Say 'next question' to continue!` :
        `Correct! Your score is now ${currentGame.score}. Say 'next question' to continue!`;
      currentGame.currentQuestion = null;
    } else {
      response = "Sorry, that's not correct. Try again, say 'hint' for a clue, or 'skip' to move on.";
    }
  }
  else if (lowerMessage.includes('stop trivia') || lowerMessage.includes('end trivia')) {
    response = `Game ended. Your final score was ${currentGame.score}. Thanks for playing!`;
    currentGame.active = false;
  }
  // Standard responses if not in game mode
  else if (lowerMessage.includes('hello')) {
    response = "Hello there! Want to play a trivia game? Say 'start trivia' to begin!";
  } else if (lowerMessage.includes('weather')) {
    response = "I don't have real-time weather data, but I hope it's sunny where you are!";
  } else if (lowerMessage.includes('name')) {
    response = "I'm a Trivia Bot. Nice to meet you! Say 'start trivia' to play a game.";
  } else {
    response = `You said: "${message}". Try saying 'start trivia' to play a fun trivia game!`;
  }

  res.json({ message: { role: 'assistant', content: response } });
});

// 2. TOOLS ENDPOINT - SLOP compatible
app.get('/tools', (req, res) => {
  res.json({ 
    tools: [
      { 
        id: 'trivia', 
        description: 'Play a trivia game with questions on various subjects' 
      },
      { 
        id: 'hint', 
        description: 'Get a hint for the current question in the trivia game' 
      },
      { 
        id: 'score', 
        description: 'Check your current score in the trivia game' 
      }
    ] 
  });
});

// Tool execution endpoint
app.post('/tools/:tool_id', (req, res) => {
  const toolId = req.params.tool_id;
  
  // Ensure req.body is initialized even if no JSON body is sent
  req.body = req.body || {};
  
  switch(toolId) {
    case 'trivia':
      if (!currentGame.active) {
        currentGame = {
          active: true,
          currentQuestion: null,
          score: 0,
          askedQuestions: [],
          hintUsed: false
        };
        res.json({ result: "Trivia game started! Say 'next question' to begin." });
      } else {
        res.json({ result: "You're already in a trivia game! Say 'next question' for a new question or 'end trivia' to stop." });
      }
      break;
      
    case 'hint':
      if (currentGame.active && currentGame.currentQuestion) {
        currentGame.hintUsed = true;
        res.json({ result: `Hint: ${currentGame.currentQuestion.hint}` });
      } else {
        res.json({ result: "No active question to give a hint for. Start a game with 'start trivia' first!" });
      }
      break;
      
    case 'score':
      if (currentGame.active) {
        res.json({ 
          result: `Your current score is ${currentGame.score}. You've answered ${currentGame.askedQuestions.length} questions.` 
        });
      } else {
        res.json({ result: "No active game. Start a new game with 'start trivia'!" });
      }
      break;
      
    default:
      res.status(404).json({ error: "Tool not found" });
  }
});

// 3. MEMORY ENDPOINT - SLOP compatible
app.post('/memory', (req, res) => {
  const { key, value } = req.body;
  if (key && value !== undefined) {
    memory.set(key, value);
    res.json({ status: 'stored' });
  } else {
    res.status(400).json({ error: 'Both key and value are required' });
  }
});

app.get('/memory/:key', (req, res) => {
  const { key } = req.params;
  if (memory.has(key)) {
    res.json({ value: memory.get(key) });
  } else {
    res.status(404).json({ error: 'Key not found' });
  }
});

app.get('/memory', (req, res) => {
  const keys = Array.from(memory.keys()).map(key => ({
    key,
    created_at: new Date().toISOString()
  }));
  res.json({ keys });
});

// 4. RESOURCES ENDPOINT - SLOP compatible
app.get('/resources', (req, res) => {
  res.json({ 
    resources: [
      { 
        id: 'trivia-questions', 
        title: 'Available Trivia Questions',
        type: 'collection' 
      },
      { 
        id: 'commands', 
        title: 'Trivia Game Commands',
        type: 'guide' 
      }
    ] 
  });
});

app.get('/resources/:id', (req, res) => {
  const resourceId = req.params.id;
  
  switch (resourceId) {
    case 'trivia-questions':
      // Return number of available questions and categories
      res.json({
        id: 'trivia-questions',
        title: 'Available Trivia Questions',
        content: `There are ${triviaQuestions.length} questions available covering topics like geography, science, art, and more.`,
        metadata: {
          count: triviaQuestions.length,
          last_updated: new Date().toISOString()
        }
      });
      break;
      
    case 'commands':
      res.json({
        id: 'commands',
        title: 'Trivia Game Commands',
        content: "Available commands: 'start trivia', 'next question', 'hint', 'skip', 'end trivia'",
        metadata: {
          command_count: 5,
          last_updated: new Date().toISOString()
        }
      });
      break;
      
    default:
      res.status(404).json({ error: 'Resource not found' });
  }
});

// Simple search for resources
app.get('/resources/search', (req, res) => {
  const query = req.query.q?.toLowerCase() || '';
  
  const results = [];
  
  if (query.includes('trivia') || query.includes('question')) {
    results.push({
      id: 'trivia-questions',
      title: 'Available Trivia Questions',
      type: 'collection',
      score: 0.95
    });
  }
  
  if (query.includes('command') || query.includes('help')) {
    results.push({
      id: 'commands',
      title: 'Trivia Game Commands',
      type: 'guide',
      score: 0.90
    });
  }
  
  res.json({ results });
});

// 5. PAY ENDPOINT - SLOP compatible (mock implementation)
app.post('/pay', (req, res) => {
  // Simple mock implementation
  const transactionId = `tx_${Date.now()}`;
  
  // Store transaction in memory
  memory.set(transactionId, {
    amount: req.body.amount || 0,
    currency: req.body.currency || 'USD',
    description: req.body.description || 'Trivia game usage',
    status: 'success',
    created_at: new Date().toISOString()
  });
  
  res.json({
    transaction_id: transactionId,
    status: 'success',
    receipt_url: `https://api.example.com/receipts/${transactionId}`
  });
});

app.get('/pay/:id', (req, res) => {
  const { id } = req.params;
  
  if (memory.has(id)) {
    const transaction = memory.get(id);
    res.json({
      transaction_id: id,
      ...transaction
    });
  } else {
    res.status(404).json({ error: 'Transaction not found' });
  }
});

// Start the server
app.listen(3000, '0.0.0.0', () => console.log('✨ SLOP running on port 3000'));

----------------------
EXAMPLES\REPLIT\README.MD
----------------------
# 2 Minute SLOP Server Implementation in Replit 🚀

This guide helps non-developers create and run a SLOP (Simple Language Open Protocol) server with a public URL in less than 5 minutes using Replit - no coding experience required!

## What is SLOP?

SLOP (Simple Language Open Protocol) is a pattern for AI APIs with 5 basic endpoints:
- `POST /chat` - Talk to AI
- `POST /tools` - Use tools
- `POST /memory` - Remember stuff
- `GET /resources` - Get knowledge/files/data
- `POST /pay` - Handle money

It's designed to make AI services work through plain web requests using patterns we've used for decades.

## Step 1: Create a Replit Account

1. Go to [replit.com](https://replit.com) and sign up for a free account

## Step 2: Create a New Repl

1. Click the "+ Create" button in the top-left corner
2. Select "Template" and search for "Node.js"
3. Name your project something like "my-slop-server"
4. Click "Create Repl"

## Step 3: Copy the SLOP Server Code

1. Delete any existing code in the main file (usually `index.js`)
2. Paste this minimal SLOP server code:

```javascript
const express = require('express');
const app = express();
app.use(express.json());

// Serve static files from the 'public' directory
app.use(express.static('public'));

// Minimum viable SLOP endpoints
app.post('/chat', (req, res) => {
  // Get the message from the request
  const message = req.body.messages?.[0]?.content || '';
  
  // Simple response - you can make this more interactive!
  const response = `You said: "${message}". This is your SLOP server responding!`;
  
  res.json({ message: { role: 'assistant', content: response } });
});

app.get('/tools', (req, res) => {
  res.json({ tools: [{ id: 'greeter', description: 'Says hello' }] });
});

app.post('/memory', (req, res) => {
  res.json({ status: 'stored' });
});

app.get('/resources', (req, res) => {
  res.json({ resources: [{ id: 'greeting', content: 'Hello, world!' }] });
});

app.post('/pay', (req, res) => {
  res.json({ transaction_id: 'tx_hello_world' });
});

app.listen(3000, () => console.log('✨ SLOP running on port 3000'));
```

## Step 4: Install Required Package

1. In the Shell (console at the bottom), type this command and hit Enter:
```
npm install express
```

## Step 5: Create a Simple HTML Interface

1. In your Replit project, click the "Files" panel (left side)
2. Click the "+" button to create a new file
3. Name it `public/index.html` (Replit will create the public folder automatically)
4. Paste this code into your new `index.html` file:

```html
<!DOCTYPE html>
<html>
<head>
  <title>My SLOP Chat</title>
  <style>
    body { font-family: Arial; max-width: 600px; margin: 0 auto; padding: 20px; }
    #chat-container { border: 1px solid #ccc; height: 300px; overflow-y: auto; padding: 10px; margin-bottom: 10px; }
    #user-input { width: 80%; padding: 8px; }
    button { padding: 8px 16px; background: #4CAF50; color: white; border: none; cursor: pointer; }
  </style>
</head>
<body>
  <h1>SLOP Chat</h1>
  <div id="chat-container"></div>
  <input type="text" id="user-input" placeholder="Type your message...">
  <button onclick="sendMessage()">Send</button>

  <script>
    function addMessage(role, content) {
      const chatContainer = document.getElementById('chat-container');
      const messageDiv = document.createElement('div');
      messageDiv.innerHTML = `<strong>${role}:</strong> ${content}`;
      chatContainer.appendChild(messageDiv);
      chatContainer.scrollTop = chatContainer.scrollHeight;
    }

    async function sendMessage() {
      const input = document.getElementById('user-input');
      const message = input.value.trim();
      
      if (!message) return;
      
      // Display user message
      addMessage('You', message);
      input.value = '';
      
      try {
        // Send to chat endpoint
        const response = await fetch('/chat', {
          method: 'POST',
          headers: { 'Content-Type': 'application/json' },
          body: JSON.stringify({
            messages: [{ role: 'user', content: message }]
          })
        });
        
        const data = await response.json();
        
        // Display assistant message
        addMessage('Assistant', data.message.content);
      } catch (error) {
        addMessage('Error', 'Failed to get response');
        console.error(error);
      }
    }

    // Allow sending with Enter key
    document.getElementById('user-input').addEventListener('keypress', function(e) {
      if (e.key === 'Enter') sendMessage();
    });
  </script>
</body>
</html>
```

## Step 6: Run Your Server

1. Click the "Run" button at the top of Replit
2. Wait for the server to start (you'll see "✨ SLOP running on port 3000")

## Step 7: Access Your Public URL

1. Look at the top-right side of the Replit interface for the "Webview" tab
2. Click on it to see your running app with the chat interface
3. The URL in the browser tab is your public SLOP server address!

## Testing Your SLOP Server

You can test your server in several ways:

1. Use the web interface to chat with your server
2. Add `/tools` to the end of your public URL to see the available tools:
   - Your URL will look like: `https://my-slop-server.yourusername.repl.co/tools`

## Using the Replit Console to Test Endpoints

You can use the built-in Replit console to test your other endpoints:

```bash
# In the Replit Shell, test your chat endpoint
curl -X POST https://my-slop-server.yourusername.repl.co/chat -H "Content-Type: application/json" -d '{"messages":[{"content":"Hello SLOP!"}]}'

# Test tools endpoint
curl https://my-slop-server.yourusername.repl.co/tools

# Test memory endpoint
curl -X POST https://my-slop-server.yourusername.repl.co/memory -H "Content-Type: application/json" -d '{"key":"test","value":"hello world"}'

# Test resources endpoint
curl https://my-slop-server.yourusername.repl.co/resources

# Test pay endpoint
curl -X POST https://my-slop-server.yourusername.repl.co/pay -H "Content-Type: application/json" -d '{}'
```

## Making It More Interesting

To make your SLOP server more interesting, you can modify the response in the `/chat` endpoint to do different things:

```javascript
app.post('/chat', (req, res) => {
  const message = req.body.messages?.[0]?.content || '';
  
  // Simple keyword response system
  let response = '';
  
  if (message.toLowerCase().includes('hello')) {
    response = "Hello there! How can I help you today?";
  } else if (message.toLowerCase().includes('weather')) {
    response = "I don't have real-time weather data, but I hope it's sunny where you are!";
  } else if (message.toLowerCase().includes('name')) {
    response = "I'm a simple SLOP server. Nice to meet you!";
  } else {
    response = `You said: "${message}". What else would you like to talk about?`;
  }
  
  res.json({ message: { role: 'assistant', content: response } });
});
```

Just update this part of your code, click "Run" again, and you'll have a slightly smarter chat interface!

## Congratulations!

You now have a working SLOP server with a public URL and a web interface that anyone can access! The URL is persistent as long as you keep your Replit account.

Replit automatically gives you a public URL for your server, making it incredibly easy to share your SLOP implementation with others without needing to understand deployment, hosting, or server management!

## Learn More About SLOP

To learn more about the SLOP protocol, visit the [SLOP GitHub repository](https://github.com/agnt-gg/slop).

----------------------
EXAMPLES\STREAMLIT\MAKEFILE
----------------------
# Makefile

# Variables
PYTHON = python3
FLASK_APP = slop_with_models.py
STREAMLIT_APP = streamlit_slop_with_models.py
VARS_FILE = vars.sh

# Default target
.PHONY: all
all: setup

# Setup virtual environment and install dependencies (optional)
.PHONY: setup
setup:
	$(PYTHON) -m venv venv
	./venv/bin/pip install --upgrade pip
	./venv/bin/pip install -r requirements.txt

# Run Flask server with environment variables
.PHONY: slop-flask
slop-flask:
	source $(VARS_FILE) && $(PYTHON) $(FLASK_APP)

# Run Streamlit app
.PHONY: slop-streamlit
slop-streamlit:
	./venv/bin/streamlit run $(STREAMLIT_APP)

# Clean up virtual environment
.PHONY: clean
clean:
	rm -rf venv

----------------------
EXAMPLES\STREAMLIT\README.MD
----------------------
# SLOP Streamlit Example

Streamlit-based SLOP example with dynamic model endpoints. It explains the purpose, setup, usage, and structure in a clear and concise way.

This is a Python implementation of the [SLOP pattern](https://github.com/agnt-gg/slop) using Flask as a backend server and Streamlit as a frontend interface. It dynamically discovers and utilizes language models from OpenAI-compatible endpoints (e.g., vLLM, Ollama, etc.) specified via environment variables.

## Features

- **Chat**: Send messages to dynamically discovered AI models.
- **Tools**: Use simple tools like a calculator and greeter.
- **Memory**: Store and retrieve key-value pairs.
- **Resources**: Access predefined static content.
- **Pay**: Simulate a payment transaction.

## Prerequisites

- Python 3.8+
- A terminal to run commands
- Optional: Access to OpenAI-compatible model endpoints (e.g., `https://hermes.ai.unturf.com/v1`)

## Setup

1. **Clone the Repository**:
   ```bash
   git clone https://github.com/agnt-gg/slop
   cd slop/examples/streamlit
   ```

2. **Set Up Virtual Environment**:

   ```bash
   make setup
   ```
   This creates a virtual environment (`venv`) and installs dependencies from `requirements.txt`.

3. **Configure Model Endpoints**:
   Edit `vars.sh` to specify your model endpoints:

   ```bash
   # vars.sh
   export MODEL_ENDPOINT_0=https://hermes.ai.unturf.com/v1
   export MODEL_ENDPOINT_1=https://node2.naptha.ai/inference
   export MODEL_ENDPOINT_2=https://node3.naptha.ai/inference
   ```
   - Gaps in numbering (e.g., skipping `MODEL_ENDPOINT_1`) are supported.
   - API keys are optional; defaults to `"not-needed"` if unset (e.g., `export MODEL_API_KEY_0=your-key`).

## Usage

1. **Run the Flask Server**:
   Open a terminal and start the backend:

   ```bash
   make slop-flask
   ```
   - This sources `vars.sh` and runs `slop_with_models.py` on `http://localhost:31337`.
   - Logs will show model discovery (e.g., `Loaded models: [model1, endpoint_7:default]`).

2. **Run the Streamlit App**:
   Open a second terminal and start the frontend:

   ```bash
   make slop-streamlit
   ```
   - Opens in your browser at `http://localhost:8501`.
   - Displays a UI with Chat, Tools, Memory, Resources, and Pay sections.

3. **Interact**:
   - **Chat**: Select a model from the dropdown and send a message.
   - **Tools**: Use the calculator or greeter.
   - **Memory**: Store/retrieve values.
   - **Resources**: View static content.
   - **Pay**: Simulate a transaction.

4. **Clean Up** (optional):

   ```bash
   make clean
   ```
   Removes the virtual environment.

## Files

- **`slop_with_models.py`**: Flask server implementing the SLOP pattern with dynamic model discovery.
- **`streamlit_slop_with_models.py`**: Streamlit frontend for user interaction.
- **`Makefile`**: Simplifies ``make setup`` and running with ``make slop-flask`` and ``make slop-streamlit``.
- **`vars.sh`**: Environment variables for model endpoints. Feel free to start with ``vars.sh.sample``!
- **`requirements.txt`**: Dependencies

## How It Works

1. **Model Discovery**:
   - The Flask server scans `MODEL_ENDPOINT_0` to `MODEL_ENDPOINT_999` from `vars.sh`.
   - Queries each endpoint’s `/v1/models` using the OpenAI client.
   - Maps model IDs to their respective clients

2. **API Endpoints**:
   - `/models`: Returns the list of discovered models.
   - `/chat`: Handles chat completions with the selected model.
   - `/tools`, `/memory`, `/resources`, `/pay`: Implement SLOP pattern features.

3. **Frontend**:
   - Streamlit fetches the model list from `/models` and provides a dropdown.
   - Sends requests to Flask for chat and other functionalities.

## Troubleshooting

- **No Models in Dropdown**:
  - Check Flask logs (`make slop-flask`) for errors (e.g., `Failed to list models for endpoint_X`).
  - Test endpoints with `curl <endpoint>/v1/models` to ensure they’re OpenAI-compatible.
- **Server Not Responding**:
  - Ensure Flask is running (`make slop-flask`) before starting Streamlit.
- **Environment Variables**:
  - Verify `vars.sh` is correct and sourced (`source vars.sh; echo $MODEL_ENDPOINT_0`).

## Dependencies

Listed in `requirements.txt`:
- `flask`: Backend server
- `streamlit`: Frontend UI
- `openai`: Client for model endpoints
- `requests`: HTTP requests in Streamlit

## Learn More

- [SLOP Specification](https://github.com/agnt-gg/slop)

This example demonstrates a flexible, extensible SLOP implementation with a modern UI. Contributions and feedback are welcome!

---

This is research into the genesis of of the future https://slop.unturf.com/

The code in this example is Public Domain.

----------------------
EXAMPLES\STREAMLIT\REQUIREMENTS.TXT
----------------------
flask
streamlit
openai
requests
flask_swagger_ui

----------------------
EXAMPLES\STREAMLIT\SLOP_WITH_MODELS.PY
----------------------
# slop_with_models.py
from flask import Flask, request, jsonify
from datetime import datetime
import os
from openai import OpenAI
import logging
from flask_swagger_ui import get_swaggerui_blueprint

# Configure logging
logging.basicConfig(
    level=logging.DEBUG, format="%(asctime)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)

app = Flask(__name__)

# Swagger UI setup
SWAGGER_URL = "/openapi"  # URL for Swagger UI
API_URL = "/static/openapi.yaml"  # Path to the OpenAPI spec file
swaggerui_blueprint = get_swaggerui_blueprint(
    SWAGGER_URL, API_URL, config={"app_name": "SLOP API"}
)
app.register_blueprint(swaggerui_blueprint, url_prefix=SWAGGER_URL)

# Global model-to-client map and memory
MODEL_CLIENT_MAP = {}
memory = {}

# Load endpoints
ENDPOINTS = []
for i in range(1000):
    endpoint = os.getenv(f"MODEL_ENDPOINT_{i}")
    if endpoint:
        ENDPOINTS.append(
            {
                "name": f"endpoint_{i}",
                "base_url": endpoint,
                "api_key": os.getenv(f"MODEL_API_KEY_{i}", "not-needed"),
            }
        )


def initialize_model_map():
    MODEL_CLIENT_MAP.clear()
    logger.info("Initializing model map...")
    if not ENDPOINTS:
        logger.warning("No endpoints configured.")
        return
    for ep in ENDPOINTS:
        base_url = ep["base_url"]
        api_key = ep["api_key"]
        endpoint_name = ep["name"]
        logger.info(f"Querying endpoint: {endpoint_name} ({base_url})")
        client = OpenAI(base_url=base_url, api_key=api_key)
        try:
            response = client.models.list()
            model_list = response.data
            logger.debug(
                f"{endpoint_name} returned models: {[m.id for m in model_list]}"
            )
        except Exception as e:
            logger.error(
                f"Skipping, Failed to list models for {endpoint_name}: {str(e)}"
            )
            continue
        for m in model_list:
            model_id = m.id
            if model_id:
                if model_id in MODEL_CLIENT_MAP:
                    logger.warning(f"Duplicate model ID '{model_id}' found.")
                else:
                    MODEL_CLIENT_MAP[model_id] = client
                    logger.info(f"Added model '{model_id}'")
            else:
                logger.warning(f"Encountered model with no ID from {endpoint_name}")
    logger.info(f"Loaded models: {list(MODEL_CLIENT_MAP.keys())}")


# SLOP components
tools = {
    "calculator": {
        "id": "calculator",
        "description": "Basic math",
        "execute": lambda params: {"result": eval(params["expression"])},
    },
    "greet": {
        "id": "greet",
        "description": "Says hello",
        "execute": lambda params: {"result": f"Hello, {params['name']}!"},
    },
}
resources = {"hello": {"id": "hello", "content": "Hello, SLOP!"}}


# Endpoints
@app.route("/chat", methods=["POST"])
def chat():
    data = request.json
    message = data["messages"][0]["content"] if data.get("messages") else "nothing"
    model_id = data.get("model") or (
        list(MODEL_CLIENT_MAP.keys())[0] if MODEL_CLIENT_MAP else None
    )
    if not model_id or model_id not in MODEL_CLIENT_MAP:
        logger.error(f"Invalid or missing model_id: {model_id}")
        return jsonify({"error": "Model not found"}), 404
    client = MODEL_CLIENT_MAP[model_id]
    try:
        response = client.chat.completions.create(
            model=model_id,
            messages=[
                {"role": m["role"], "content": m["content"]}
                for m in data.get("messages", [])
            ]
            or [{"role": "user", "content": message}],
        )
        logger.debug(
            f"Chat response for model {model_id}: {response.choices[0].message.content}"
        )
        return (
            jsonify(
                {
                    "choices": [
                        {"message": {"content": response.choices[0].message.content}}
                    ]
                }
            ),
            200,
        )
    except Exception as e:
        logger.error(f"Chat error with model {model_id}: {str(e)}")
        return jsonify({"error": str(e)}), 500


@app.route("/models", methods=["GET"])
def list_models():
    models = list(MODEL_CLIENT_MAP.keys())
    logger.debug(f"Returning models: {models}")
    return jsonify({"models": models}), 200


@app.route("/tools", methods=["GET"])
def list_tools():
    return (
        jsonify(
            {
                "tools": [
                    {"id": k, "description": v["description"]} for k, v in tools.items()
                ]
            }
        ),
        200,
    )


@app.route("/tools/<tool_id>", methods=["POST"])
def use_tool(tool_id):
    if tool_id not in tools:
        return jsonify({"error": "Tool not found"}), 404
    data = request.json or {}
    if tool_id == "calculator" and "expression" not in data:
        return jsonify({"error": "Missing 'expression'"}), 400
    if tool_id == "greet" and "name" not in data:
        return jsonify({"error": "Missing 'name'"}), 400
    result = tools[tool_id]["execute"](data)
    return jsonify(result), 200


@app.route("/memory", methods=["POST"])
def store_memory():
    data = request.json
    memory[data["key"]] = data["value"]
    return jsonify({"status": "stored"}), 200


@app.route("/memory/<key>", methods=["GET"])
def get_memory(key):
    return jsonify({"value": memory.get(key)}), 200


@app.route("/memory", methods=["GET"])
def list_memory():
    return jsonify({"keys": list(memory.keys())}), 200


@app.route("/memory/<key>", methods=["DELETE"])
def delete_memory(key):
    if key not in memory:
        return jsonify({"error": "Key not found"}), 404
    del memory[key]
    return jsonify({"status": "deleted"}), 200


@app.route("/resources", methods=["GET"])
def list_resources():
    return jsonify({"resources": list(resources.values())}), 200


@app.route("/resources/<resource_id>", methods=["GET"])
def get_resource(resource_id):
    if resource_id not in resources:
        return jsonify({"error": "Resource not found"}), 404
    return jsonify(resources[resource_id]), 200


@app.route("/pay", methods=["POST"])
def pay():
    return (
        jsonify(
            {
                "transaction_id": f"tx_{int(datetime.now().timestamp())}",
                "status": "success",
            }
        ),
        200,
    )


if __name__ == "__main__":
    initialize_model_map()
    app.run(debug=True, port=31337)

----------------------
EXAMPLES\STREAMLIT\STATIC\OPENAPI.YAML
----------------------
openapi: 3.0.0
info:
  title: SLOP API
  description: A SLOP pattern implementation with dynamic model endpoints
  version: 1.0.0
servers:
  - url: http://localhost:31337
    description: Local development server
paths:
  /chat:
    post:
      summary: Send a message to an AI model
      tags:
        - Chat
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/ChatRequest'
      responses:
        '200':
          description: Successful response with AI message
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ChatResponse'
        '404':
          description: Model not found
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorResponse'
        '500':
          description: Server error
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorResponse'
  /models:
    get:
      summary: List available models
      tags:
        - Models
      responses:
        '200':
          description: List of model IDs
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ModelsResponse'
  /tools:
    get:
      summary: List available tools
      tags:
        - Tools
      responses:
        '200':
          description: List of tools
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ToolsResponse'
  /tools/{tool_id}:
    post:
      summary: Use a specific tool
      tags:
        - Tools
      parameters:
        - name: tool_id
          in: path
          required: true
          schema:
            type: string
            enum: [calculator, greet]
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/ToolRequest'
      responses:
        '200':
          description: Tool execution result
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ToolResponse'
        '400':
          description: Missing required parameter
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorResponse'
        '404':
          description: Tool not found
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorResponse'
  /memory:
    get:
      summary: List all memory keys
      tags:
        - Memory
      responses:
        '200':
          description: List of memory keys
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/MemoryListResponse'
    post:
      summary: Store a key-value pair
      tags:
        - Memory
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/MemoryStoreRequest'
      responses:
        '200':
          description: Successfully stored
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/MemoryStoreResponse'
  /memory/{key}:
    get:
      summary: Retrieve a value by key
      tags:
        - Memory
      parameters:
        - name: key
          in: path
          required: true
          schema:
            type: string
      responses:
        '200':
          description: Retrieved value
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/MemoryGetResponse'
    delete:
      summary: Delete a memory key
      tags:
        - Memory
      parameters:
        - name: key
          in: path
          required: true
          schema:
            type: string
      responses:
        '200':
          description: Successfully deleted
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/MemoryStoreResponse'
        '404':
          description: Key not found
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorResponse'
  /resources:
    get:
      summary: List available resources
      tags:
        - Resources
      responses:
        '200':
          description: List of resources
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ResourcesResponse'
  /resources/{resource_id}:
    get:
      summary: Get a specific resource
      tags:
        - Resources
      parameters:
        - name: resource_id
          in: path
          required: true
          schema:
            type: string
      responses:
        '200':
          description: Resource content
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ResourceResponse'
        '404':
          description: Resource not found
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorResponse'
  /pay:
    post:
      summary: Simulate a payment
      tags:
        - Pay
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/PayRequest'
      responses:
        '200':
          description: Payment simulation result
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/PayResponse'
components:
  schemas:
    ChatRequest:
      type: object
      properties:
        messages:
          type: array
          items:
            $ref: '#/components/schemas/Message'
        model:
          type: string
          nullable: true
      required:
        - messages
    Message:
      type: object
      properties:
        role:
          type: string
          enum: [user, assistant, system]
        content:
          type: string
      required:
        - role
        - content
    ChatResponse:
      type: object
      properties:
        choices:
          type: array
          items:
            type: object
            properties:
              message:
                type: object
                properties:
                  content:
                    type: string
            required:
              - message
      required:
        - choices
    ModelsResponse:
      type: object
      properties:
        models:
          type: array
          items:
            type: string
      required:
        - models
    ToolsResponse:
      type: object
      properties:
        tools:
          type: array
          items:
            type: object
            properties:
              id:
                type: string
              description:
                type: string
            required:
              - id
              - description
      required:
        - tools
    ToolRequest:
      type: object
      properties:
        expression:
          type: string
          nullable: true
        name:
          type: string
          nullable: true
    ToolResponse:
      type: object
      properties:
        result:
          oneOf:
            - type: string
            - type: integer
      required:
        - result
    MemoryStoreRequest:
      type: object
      properties:
        key:
          type: string
        value:
          type: string
      required:
        - key
        - value
    MemoryStoreResponse:
      type: object
      properties:
        status:
          type: string
          enum: [stored, deleted]
      required:
        - status
    MemoryGetResponse:
      type: object
      properties:
        value:
          type: string
          nullable: true
      required:
        - value
    MemoryListResponse:
      type: object
      properties:
        keys:
          type: array
          items:
            type: string
      required:
        - keys
    ResourcesResponse:
      type: object
      properties:
        resources:
          type: array
          items:
            type: object
            properties:
              id:
                type: string
              content:
                type: string
            required:
              - id
              - content
      required:
        - resources
    ResourceResponse:
      type: object
      properties:
        id:
          type: string
        content:
          type: string
      required:
        - id
        - content
    PayRequest:
      type: object
      properties:
        amount:
          type: number
          format: float
      required:
        - amount
    PayResponse:
      type: object
      properties:
        transaction_id:
          type: string
        status:
          type: string
          enum: [success]
      required:
        - transaction_id
        - status
    ErrorResponse:
      type: object
      properties:
        error:
          type: string
      required:
        - error

----------------------
EXAMPLES\STREAMLIT\STREAMLIT_SLOP_WITH_MODELS.PY
----------------------
# streamlit_slop_with_models.py
import streamlit as st
import requests

BASE_URL = "http://localhost:31337"


def main():
    st.title("SLOP Streamlit with Dynamic Models")
    st.markdown(
        "[Explore API Documentation](http://localhost:31337/openapi/)",
        unsafe_allow_html=True,
    )
    page = st.sidebar.selectbox(
        "Choose a feature", ["Chat", "Tools", "Memory", "Resources", "Pay"]
    )
    if page == "Chat":
        chat_interface()
    elif page == "Tools":
        tools_interface()
    elif page == "Memory":
        memory_interface()
    elif page == "Resources":
        resources_interface()
    elif page == "Pay":
        pay_interface()


def chat_interface():
    st.header("Chat")

    try:
        response = requests.get(f"{BASE_URL}/models", timeout=5)
        response.raise_for_status()
        models = response.json()["models"]
    except requests.RequestException as e:
        st.warning(f"Could not fetch models: {str(e)}")
        models = []

    selected_model = st.selectbox(
        "Select Model", models if models else ["No models available"]
    )

    if "chat_history" not in st.session_state:
        st.session_state.chat_history = []

    for entry in st.session_state.chat_history:
        st.write(f"**User**: {entry['user']}")
        st.write(f"**Assistant**: {entry['assistant']}")

    with st.form(key="chat_form", clear_on_submit=True):
        message = st.text_area("Enter your message", height=100, key="chat_input")
        submit_button = st.form_submit_button(label="Submit", type="primary")

        st.markdown(
            """
            <script>
            const textarea = document.querySelector('textarea');
            textarea.addEventListener('keydown', function(event) {
                if (event.key === 'Enter' && !event.shiftKey) {
                    event.preventDefault();
                    document.querySelector('button[type="submit"]').click();
                }
            });
            </script>
        """,
            unsafe_allow_html=True,
        )

        if submit_button and message and models:
            try:
                response = requests.post(
                    f"{BASE_URL}/chat",
                    json={
                        "messages": [{"role": "user", "content": message}],
                        "model": selected_model,
                    },
                    timeout=5,
                )
                response.raise_for_status()
                assistant_response = response.json()["choices"][0]["message"]["content"]
                st.session_state.chat_history.append(
                    {"user": message, "assistant": assistant_response}
                )
                st.rerun()
            except requests.RequestException as e:
                st.error(f"Error: {str(e)}")


def tools_interface():
    st.header("Tools")
    try:
        response = requests.get(f"{BASE_URL}/tools", timeout=5)
        response.raise_for_status()
        tools = response.json()["tools"]
    except requests.RequestException as e:
        st.warning(f"Could not fetch tools: {str(e)}")
        tools = []

    if not tools:
        st.write("No tools available.")
        return

    tool_id = st.selectbox("Select a tool", [t["id"] for t in tools])

    if tool_id == "calculator":
        expression = st.text_input("Enter expression (e.g., 2 + 2)")
        if st.button("Calculate"):
            try:
                response = requests.post(
                    f"{BASE_URL}/tools/{tool_id}",
                    json={"expression": expression},
                    timeout=5,
                )
                response.raise_for_status()
                st.write(f"Result: {response.json()['result']}")
            except requests.RequestException as e:
                st.error(f"Error: {str(e)}")

    elif tool_id == "greet":
        name = st.text_input("Enter name")
        if st.button("Greet"):
            try:
                response = requests.post(
                    f"{BASE_URL}/tools/{tool_id}", json={"name": name}, timeout=5
                )
                response.raise_for_status()
                st.write(response.json()["result"])
            except requests.RequestException as e:
                st.error(f"Error: {str(e)}")


def memory_interface():
    st.header("Memory")
    action = st.radio("Action", ["Store", "Retrieve", "List", "Delete"])

    if action == "Store":
        key = st.text_input("Key")
        value = st.text_input("Value")
        if st.button("Store"):
            try:
                response = requests.post(
                    f"{BASE_URL}/memory", json={"key": key, "value": value}, timeout=5
                )
                response.raise_for_status()
                st.success("Stored successfully!")
                list_response = requests.get(f"{BASE_URL}/memory", timeout=5)
                list_response.raise_for_status()
                keys = list_response.json()["keys"]
                st.write("Current Memory Keys:", ", ".join(keys) if keys else "None")
            except requests.RequestException as e:
                st.error(f"Error: {str(e)}")

    elif action == "Retrieve":
        key = st.text_input("Key to retrieve")
        if st.button("Retrieve"):
            try:
                response = requests.get(f"{BASE_URL}/memory/{key}", timeout=5)
                response.raise_for_status()
                value = response.json()["value"]
                st.write(f"Value: {value if value is not None else 'Not found'}")
            except requests.RequestException as e:
                st.error(f"Error: {str(e)}")

    elif action == "List":
        if st.button("List All Keys"):
            try:
                response = requests.get(f"{BASE_URL}/memory", timeout=5)
                response.raise_for_status()
                keys = response.json()["keys"]
                st.write("Memory Keys:", ", ".join(keys) if keys else "None")
            except requests.RequestException as e:
                st.error(f"Error: {str(e)}")

    elif action == "Delete":
        key = st.text_input("Key to delete")
        if st.button("Delete"):
            try:
                response = requests.delete(f"{BASE_URL}/memory/{key}", timeout=5)
                response.raise_for_status()
                st.success("Deleted successfully!")
                list_response = requests.get(f"{BASE_URL}/memory", timeout=5)
                list_response.raise_for_status()
                keys = list_response.json()["keys"]
                st.write("Current Memory Keys:", ", ".join(keys) if keys else "None")
            except requests.RequestException as e:
                st.error(f"Error: {str(e)}")


def resources_interface():
    st.header("Resources")
    try:
        response = requests.get(f"{BASE_URL}/resources", timeout=5)
        response.raise_for_status()
        resources = response.json()["resources"]
    except requests.RequestException as e:
        st.warning(f"Could not fetch resources: {str(e)}")
        resources = []

    if not resources:
        st.write("No resources available.")
        return

    resource_id = st.selectbox("Select resource", [r["id"] for r in resources])
    if st.button("Get Resource"):
        try:
            response = requests.get(f"{BASE_URL}/resources/{resource_id}", timeout=5)
            response.raise_for_status()
            st.write(response.json().get("content", response.json()))
        except requests.RequestException as e:
            st.error(f"Error: {str(e)}")


def pay_interface():
    st.header("Pay")
    amount = st.number_input("Amount", min_value=0.0, step=0.01)
    if st.button("Pay"):
        try:
            response = requests.post(
                f"{BASE_URL}/pay", json={"amount": amount}, timeout=5
            )
            response.raise_for_status()
            st.write(f"Transaction ID: {response.json()['transaction_id']}")
            st.write(f"Status: {response.json()['status']}")
        except requests.RequestException as e:
            st.error(f"Error: {str(e)}")


if __name__ == "__main__":
    main()

----------------------
EXAMPLES\STREAMLIT\VARS.SH.EXAMPLE
----------------------
export MODEL_ENDPOINT_1=https://hermes.ai.unturf.com/v1
export MODEL_ENDPOINT_2=https://node2.naptha.ai/inference
export MODEL_ENDPOINT_3=https://node3.naptha.ai/inference

----------------------
LICENSE
----------------------
MIT License

Copyright (c) 2025 agnt.gg

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.

----------------------
README.MD
----------------------
# SLOP: Simple Language Open Protocol

> **Because AI shouldn't be complicated**

### 🎯 WHAT SLOP IS:
- A pattern for AI APIs with 5 basic endpoints
- Regular HTTP(S) requests with JSON data
- A standard way to talk to any AI service
- Based on REST: GET and POST what you need

### 🚫 WHAT SLOP IS NOT:
- A framework or library you install
- A new technology or language
- A specific company's product
- An additional abstraction in any way

> 💡 **SLOP simply says:** "AI services should work through plain web requests using patterns we've used for decades."

That's it. Just a pattern. ✨

---

![Star History Chart](https://api.star-history.com/svg?repos=agnt-gg/slop&type=Date)

---

## 1. CORE BELIEFS
- Everything is an HTTP request
- Every tool is an API endpoint
- Every AI is accessible
- Every developer is welcome

## 2. MINIMUM VIABLE ENDPOINTS
- `POST /chat` // Talk to AI
- `POST /tools` // Use tools
- `POST /memory` // Remember stuff
- `GET /resources` // Get knowledge/files/data
- `POST /pay` // Handle money

## 3. CONNECTION TYPES
- Standard HTTP/REST Interface For Most Things
- WebSocket Support for Persistent Real-Time Connections
- Server-Sent Events (SSE) for One-Way Real-Time Streaming

## 4. MULTI-AGENT CAPABILITIES
- Route Queries to Specialized Agents Based on Content
- Create Agent Networks with Different Skills and Roles
- Support for Multiple Execution Patterns (Sequential, Parallel, Branching)
- Persistent Memory Allows Seamless Agent Collaboration
- Works for Simple to Complex Use Cases:

  - [Advanced Streaming AI Chat Platform](https://github.com/agnt-gg/slop/tree/main/examples/javascript/advanced-examples/pdf-bot-with-stream)
  - Customer Service Bots with Specialist Routing
  - Research Assistants with Domain-Specific Agents
  - Creative Workflows with Multiple AI Collaborators
  - Game Development with Dynamic NPCs
  - Smart Home Management with Coordinated AI Agents
  - Personal Finance Management with Adaptive Advisors
  - Educational Platforms with Adaptive Learning Agents
  - Multi-Agent Disaster Response Coordination
  - Marketing Automation with Targeted Campaign Agents
  - Health Monitoring Systems with Specialized Health Agents
  - Travel Planning Assistants with Itinerary Optimization
  - E-commerce Platforms with Personalized Shopping Assistants
  - Content Moderation Systems with Specialized Review Agents

---

## 🤝 THE SLOP PROMISE:

### 1. OPEN
- Free to use
- Open source
- No vendor lock
- Community driven
- Use any LLM model

### 2. SIMPLE
- REST based
- JSON only
- Standard HTTP
- Zero dependencies

### 3. FLEXIBLE
- Any AI model
- Any tool
- Any platform

---

## 📖 ENDPOINT OPERATIONS (v0.0.1)

### 💬 CHAT
- `POST /chat` - Send messages to AI
- `POST /chat` - Create or continue a thread (with thread_id)
- `GET /chat/:id` - Get a specific chat
- `GET /chat/thread_:id` - Get all messages in a thread
- `GET /chat` - List recent chats
- `GET /chat?type=threads` - List all threads

### 🛠️ TOOLS
- `GET /tools` - List available tools
- `POST /tools/:tool_id` - Use a specific tool
- `GET /tools/:tool_id` - Get tool details

### 🧠 MEMORY
- `POST /memory` - Store a key-value pair
- `GET /memory/:key` - Get value by key
- `GET /memory` - List all keys
- `PUT /memory/:key` - Update existing value
- `DELETE /memory/:key` - Delete a key-value pair
- `POST /memory/query` - Search with semantic query

### 📚 RESOURCES
- `GET /resources` - List available resources
- `GET /resources/:id` - Get a specific resource
- `GET /resources/search?q=query` - Search resources

### 💳 PAY
- `POST /pay` - Create a payment
- `GET /pay/:id` - Get payment status

---

## 🚀 API EXAMPLES - ALL ENDPOINTS

### 💬 CHAT ENDPOINTS

#### POST /chat
```json
// REQUEST
POST /chat
{
  "messages": [
    {"role": "user", "content": "Hello, what's the weather like?"}
  ],
  "model": "any-model-id"
}

// RESPONSE
{
  "id": "chat_123",
  "message": {
    "role": "assistant", 
    "content": "I don't have real-time weather data. You could check a weather service for current conditions."
  }
}
```

#### GET /chat/:id
```json
// REQUEST
GET /chat/chat_123

// RESPONSE
{
  "id": "chat_123",
  "messages": [
    {"role": "user", "content": "Hello, what's the weather like?"},
    {"role": "assistant", "content": "I don't have real-time weather data. You could check a weather service for current conditions."}
  ],
  "model": "any-model-id",
  "created_at": "2023-05-15T10:30:00Z"
}
```

#### Creating a Thread
```json
// REQUEST
POST /chat
{
  "thread_id": "thread_12345",  // Thread identifier
  "messages": [
    {"role": "user", "content": "Let's discuss project planning"}
  ],
  "model": "any-model-id"
}

// RESPONSE
{
  "thread_id": "thread_12345",
  "message": {
    "role": "assistant", 
    "content": "Sure, I'd be happy to discuss project planning. What aspects would you like to focus on?"
  }
}
```

#### Adding to a Thread
```json
// REQUEST
POST /chat
{
  "thread_id": "thread_12345",
  "messages": [
    {"role": "user", "content": "What's our next milestone?"}
  ],
  "model": "any-model-id"
}

// RESPONSE
{
  "thread_id": "thread_12345",
  "message": {
    "role": "assistant", 
    "content": "To determine the next milestone, we should review your project timeline and priorities. What's the current state of your project?"
  }
}
```

#### Listing All Threads
```json
// REQUEST
GET /chat?type=threads

// RESPONSE
{
  "threads": [
    {
      "id": "thread_12345",
      "title": "Project Planning",
      "last_message": "What's our next milestone?",
      "created_at": "2023-05-15T10:30:00Z",
      "updated_at": "2023-05-15T11:45:00Z"
    },
    {
      "id": "thread_67890",
      "title": "Bug Fixes",
      "last_message": "Let's prioritize the login issue",
      "created_at": "2023-05-14T14:20:00Z",
      "updated_at": "2023-05-14T16:30:00Z"
    }
  ]
}
```

#### Getting Thread Messages
```json
// REQUEST
GET /chat/thread_12345

// RESPONSE
{
  "thread_id": "thread_12345",
  "title": "Project Planning",
  "messages": [
    {
      "id": "msg_001",
      "role": "user", 
      "content": "Let's discuss project planning",
      "created_at": "2023-05-15T10:30:00Z"
    },
    {
      "id": "msg_002",
      "role": "assistant", 
      "content": "Sure, what aspects of the project would you like to plan?",
      "created_at": "2023-05-15T10:30:05Z"
    },
    {
      "id": "msg_003",
      "role": "user", 
      "content": "What's our next milestone?",
      "created_at": "2023-05-15T11:45:00Z"
    }
  ],
  "model": "any-model-id",
  "created_at": "2023-05-15T10:30:00Z",
  "updated_at": "2023-05-15T11:45:00Z"
}
```

#### Storing Thread Metadata
```json
// REQUEST
POST /memory
{
  "key": "thread:thread_12345",
  "value": {
    "title": "Project Planning",
    "participants": ["user_1", "user_2"],
    "tags": ["project", "planning", "roadmap"],
    "status": "active"
  }
}

// RESPONSE
{
  "status": "stored"
}
```

#### Searching for Threads
```json
// REQUEST
POST /memory/query
{
  "query": "project planning threads with user_1",
  "filter": {
    "key_prefix": "thread:"
  }
}

// RESPONSE
{
  "results": [
    {
      "key": "thread:thread_12345",
      "value": {
        "title": "Project Planning",
        "participants": ["user_1", "user_2"],
        "tags": ["project", "planning", "roadmap"],
        "status": "active"
      },
      "score": 0.95
    }
  ]
}
```

#### Updating Thread Metadata
```json
// REQUEST
PUT /memory/thread:thread_12345
{
  "value": {
    "title": "Project Planning",
    "participants": ["user_1", "user_2", "user_3"],  // Added new participant
    "tags": ["project", "planning", "roadmap", "active"],
    "status": "in_progress"  // Updated status
  }
}

// RESPONSE
{
  "status": "updated",
  "previous_value": {
    "title": "Project Planning",
    "participants": ["user_1", "user_2"],
    "tags": ["project", "planning", "roadmap"],
    "status": "active"
  }
}
```

#### GET /chat
```json
// REQUEST
GET /chat

// RESPONSE
{
  "chats": [
    {
      "id": "chat_123",
      "snippet": "Hello, what's the weather like?",
      "created_at": "2023-05-15T10:30:00Z"
    },
    {
      "id": "chat_456",
      "snippet": "Tell me about Mars",
      "created_at": "2023-05-14T14:20:00Z"
    }
  ]
}
```

### 🛠️ TOOLS ENDPOINTS

#### GET /tools
```json
// REQUEST
GET /tools

// RESPONSE
{
  "tools": [
    {
      "id": "calculator",
      "description": "Performs mathematical calculations",
      "parameters": {
        "expression": "string"
      }
    },
    {
      "id": "weather",
      "description": "Gets current weather",
      "parameters": {
        "location": "string"
      }
    }
  ]
}
```

#### POST /tools/:tool_id
```json
// REQUEST
POST /tools/calculator
{
  "expression": "15 * 7"
}

// RESPONSE
{
  "result": 105
}
```

#### GET /tools/:tool_id
```json
// REQUEST
GET /tools/calculator

// RESPONSE
{
  "id": "calculator",
  "description": "Performs mathematical calculations",
  "parameters": {
    "expression": {
      "type": "string",
      "description": "Mathematical expression to evaluate"
    }
  },
  "example": "15 * 7"
}
```

### 🧠 MEMORY ENDPOINTS

#### POST /memory
```json
// REQUEST
POST /memory
{
  "key": "user_preference",
  "value": {
    "theme": "dark",
    "language": "en"
  }
}

// RESPONSE
{
  "status": "stored"
}
```

#### GET /memory/:key
```json
// REQUEST
GET /memory/user_preference

// RESPONSE
{
  "key": "user_preference",
  "value": {
    "theme": "dark",
    "language": "en"
  },
  "created_at": "2023-05-15T10:30:00Z"
}
```

#### GET /memory
```json
// REQUEST
GET /memory

// RESPONSE
{
  "keys": [
    {
      "key": "user_preference",
      "created_at": "2023-05-15T10:30:00Z"
    },
    {
      "key": "search_history",
      "created_at": "2023-05-14T14:20:00Z"
    }
  ]
}
```

#### PUT /memory/:key
```json
// REQUEST
PUT /memory/user_preference
{
  "value": {
    "theme": "light",
    "language": "en"
  }
}

// RESPONSE
{
  "status": "updated",
  "previous_value": {
    "theme": "dark",
    "language": "en"
  }
}
```

#### DELETE /memory/:key
```json
// REQUEST
DELETE /memory/user_preference

// RESPONSE
{
  "status": "deleted"
}
```

#### POST /memory/query
```json
// REQUEST
POST /memory/query
{
  "query": "What theme settings do I have?",
  "limit": 1
}

// RESPONSE
{
  "results": [
    {
      "key": "user_preference",
      "value": {
        "theme": "dark",
        "language": "en"
      },
      "score": 0.92
    }
  ]
}
```

### 📚 RESOURCES ENDPOINTS

#### GET /resources
```json
// REQUEST
GET /resources

// RESPONSE
{
  "resources": [
    {
      "id": "mars-101",
      "title": "Mars: The Red Planet",
      "type": "article"
    },
    {
      "id": "document-123",
      "name": "project_plan.pdf",
      "type": "file"
    }
  ]
}
```

#### GET /resources/:id
```json
// REQUEST
GET /resources/mars-101

// RESPONSE
{
  "id": "mars-101",
  "title": "Mars: The Red Planet",
  "type": "article",
  "content": "Mars is the fourth planet from the Sun and the second-smallest planet in the Solar System...",
  "metadata": {
    "source": "astronomy-db",
    "last_updated": "2023-05-10"
  }
}
```

#### GET /resources/search
```json
// REQUEST
GET /resources/search?q=mars

// RESPONSE
{
  "results": [
    {
      "id": "mars-101",
      "title": "Mars: The Red Planet",
      "type": "article",
      "score": 0.98
    },
    {
      "id": "solar-system",
      "title": "Our Solar System",
      "type": "article",
      "score": 0.75
    }
  ]
}
```

### 💳 PAY ENDPOINTS

#### POST /pay
```json
// REQUEST
POST /pay
{
  "amount": 5.00,
  "currency": "USD",
  "description": "API usage - 1000 tokens",
  "payment_method": "card_token_123"
}

// RESPONSE
{
  "transaction_id": "tx_987654",
  "status": "success",
  "receipt_url": "https://api.example.com/receipts/tx_987654"
}
```

#### GET /pay/:id
```json
// REQUEST
GET /pay/tx_987654

// RESPONSE
{
  "transaction_id": "tx_987654",
  "amount": 5.00,
  "currency": "USD",
  "description": "API usage - 1000 tokens",
  "status": "success",
  "created_at": "2023-05-15T10:30:00Z",
  "receipt_url": "https://api.example.com/receipts/tx_987654"
}
```

### 🔐 AUTH EXAMPLES

Authentication in SLOP uses standard HTTP headers. Here are examples in both JavaScript and Python:

#### JavaScript Example
```javascript
// Using fetch
const callSlop = async (endpoint, data) => {
  const response = await fetch(`https://api.example.com${endpoint}`, {
    method: 'POST',
    headers: {
      'Authorization': 'Bearer your-token-here',
      'Content-Type': 'application/json'
    },
    body: JSON.stringify(data)
  });
  return response.json();
};

// Using axios
const axios = require('axios');
const api = axios.create({
  baseURL: 'https://api.example.com',
  headers: {
    'Authorization': 'Bearer your-token-here'
  }
});

// Make authenticated requests
await api.post('/chat', {
  messages: [{ content: 'Hello!' }]
});
```

#### Python Example
```python
import requests

# Using requests
headers = {
    'Authorization': 'Bearer your-token-here',
    'Content-Type': 'application/json'
}

# Function to make authenticated requests
def call_slop(endpoint, data=None):
    base_url = 'https://api.example.com'
    method = 'GET' if data is None else 'POST'
    response = requests.request(
        method=method,
        url=f'{base_url}{endpoint}',
        headers=headers,
        json=data
    )
    return response.json()

# Make authenticated requests
chat_response = call_slop('/chat', {
    'messages': [{'content': 'Hello!'}]
})
```

Remember: SLOP uses standard HTTP auth - no special endpoints needed! 🔑

### 🛡️ SCOPE HEADERS FOR LIMITING AI SCOPE

SLOP uses standard HTTP headers to control AI safety and permissions:

```http
X-SLOP-Scope: chat.read,tools.calculator,memory.user.read
```

#### Common Scopes

chat.read # Read chat history
chat.write # Send messages
tools.* # Access all tools
tools.safe.* # Access only safe tools
memory.user.* # Full user memory access
memory..read # Read-only memory access


#### Examples

```http
# Safe: Calculator within scope
POST /tools/calculator
X-SLOP-Scope: tools.calculator.execute
{
    "expression": "2 + 2"
}

# Blocked: No execute permission
POST /tools/system-cmd
X-SLOP-Scope: tools.calculator.execute
{
    "cmd": "rm -rf /"
}

// RESPONSE
{
    "error": "Scope violation: tools.execute-code requires explicit permission",
    "permitted": false
}
```

Remember: Security through simplicity! 🔒

---


## 🔄 SSE STREAMING IN SLOP

SLOP supports streaming responses through Server-Sent Events (SSE) - perfect for token-by-token AI outputs:

### Adding SSE to Your SLOP Implementation

#### JavaScript Example
```javascript
// Add this streaming endpoint to your SLOP implementation
app.post('/chat/stream', async (req, res) => {
  const { messages } = req.body;
  const userQuery = messages[0].content;
  
  // Set SSE headers
  res.setHeader('Content-Type', 'text/event-stream');
  res.setHeader('Cache-Control', 'no-cache');
  res.setHeader('Connection', 'keep-alive');
  
  // Create streaming response
  const stream = await openai.chat.completions.create({
    model: "gpt-4",
    messages: [
      { role: "system", content: "You are a helpful assistant." },
      { role: "user", content: userQuery }
    ],
    stream: true
  });
  
  // Send tokens as they arrive
  for await (const chunk of stream) {
    const content = chunk.choices[0]?.delta?.content || '';
    if (content) {
      res.write(`data: ${JSON.stringify({ content })}\n\n`);
    }
  }
  res.write('data: [DONE]\n\n');
  res.end();
});
```

#### Python Example
```python
@app.route('/chat/stream', methods=['POST'])
def chat_stream():
    data = request.json
    user_query = data['messages'][0]['content']
    
    def generate():
        stream = openai.chat.completions.create(
            model="gpt-4",
            messages=[
                {"role": "system", "content": "You are a helpful assistant."},
                {"role": "user", "content": user_query}
            ],
            stream=True
        )
        for chunk in stream:
            content = chunk.choices[0].delta.content or ''
            if content:
                yield f"data: {json.dumps({'content': content})}\n\n"
        yield "data: [DONE]\n\n"
    
    return Response(generate(), content_type='text/event-stream')
```

#### Client Consumption
```javascript
// Browser JavaScript to consume the stream
const eventSource = new EventSource('/chat/stream');
eventSource.onmessage = (event) => {
  if (event.data === '[DONE]') {
    eventSource.close();
    return;
  }
  const data = JSON.parse(event.data);
  // Append incoming token to UI
  document.getElementById('response').innerHTML += data.content;
};
```

### Why SSE is SLOP-Friendly:
- Uses standard HTTP - no new protocols
- Works with existing authentication
- Simple implementation - minimal code
- Compatible with all HTTP clients
- Lower overhead than WebSockets

Remember: Add `/stream` suffix to endpoints that support streaming! 🚿

## 🔌 WEBSOCKET STREAMING IN SLOP

SLOP also supports WebSocket for bidirectional streaming - ideal for real-time AI interactions:

### Adding WebSocket to Your SLOP Implementation

#### JavaScript Example (Node.js with ws)
```javascript
// Server-side WebSocket implementation
const WebSocket = require('ws');
const wss = new WebSocket.Server({ port: 8080 });

wss.on('connection', (ws) => {
  ws.on('message', async (message) => {
    try {
      const data = JSON.parse(message);
      const { messages } = data;
      const userQuery = messages[0].content;
      
      // Create streaming response
      const stream = await openai.chat.completions.create({
        model: "gpt-4",
        messages: [
          { role: "system", content: "You are a helpful assistant." },
          { role: "user", content: userQuery }
        ],
        stream: true
      });
      
      // Send tokens as they arrive
      for await (const chunk of stream) {
        const content = chunk.choices[0]?.delta?.content || '';
        if (content && ws.readyState === WebSocket.OPEN) {
          ws.send(JSON.stringify({ content }));
        }
      }
      
      if (ws.readyState === WebSocket.OPEN) {
        ws.send(JSON.stringify({ status: "complete" }));
      }
    } catch (error) {
      if (ws.readyState === WebSocket.OPEN) {
        ws.send(JSON.stringify({ error: error.message }));
      }
    }
  });
});
```

#### Python Example (with FastAPI and websockets)
```python
from fastapi import FastAPI, WebSocket
import json
import openai

app = FastAPI()

@app.websocket("/chat/ws")
async def websocket_endpoint(websocket: WebSocket):
    await websocket.accept()
    
    try:
        while True:
            data = await websocket.receive_text()
            data_json = json.loads(data)
            user_query = data_json['messages'][0]['content']
            
            stream = openai.chat.completions.create(
                model="gpt-4",
                messages=[
                    {"role": "system", "content": "You are a helpful assistant."},
                    {"role": "user", "content": user_query}
                ],
                stream=True
            )
            
            for chunk in stream:
                content = chunk.choices[0].delta.content or ''
                if content:
                    await websocket.send_text(json.dumps({"content": content}))
            
            await websocket.send_text(json.dumps({"status": "complete"}))
    
    except Exception as e:
        await websocket.send_text(json.dumps({"error": str(e)}))
```

#### Client Consumption
```javascript
// Browser JavaScript to connect to WebSocket
const socket = new WebSocket('ws://localhost:8080');
let responseText = '';

// Send a message when connection is open
socket.onopen = function(event) {
  socket.send(JSON.stringify({
    messages: [{ role: 'user', content: 'Tell me about SLOP protocol' }]
  }));
};

// Listen for messages
socket.onmessage = function(event) {
  const data = JSON.parse(event.data);
  
  if (data.content) {
    responseText += data.content;
    document.getElementById('response').innerText = responseText;
  }
  
  if (data.status === 'complete') {
    console.log('Response complete');
  }
  
  if (data.error) {
    console.error('Error:', data.error);
  }
};

// Handle errors
socket.onerror = function(error) {
  console.error('WebSocket Error:', error);
};

// Clean up on close
socket.onclose = function(event) {
  console.log('Connection closed');
};
```

### Why WebSockets for SLOP:
- Bidirectional communication for complex interactions
- Persistent connection for multiple exchanges
- Real-time feedback and typing indicators
- Supports advanced features like user interruptions
- Ideal for chat applications and interactive AI assistants

Remember: Use `/ws` suffix to indicate WebSocket endpoints in your SLOP implementation! 🔌

---

Let's collab! SLOP Discord: https://discord.com/invite/nwXJMnHmXP

🎉 **Enjoy using SLOP!** 🎉 

SLOP is an open sourced protocol launched under the MIT license by [@NathanWilbanks](https://discord.com/invite/nwXJMnHmXP) of the AGNT.gg open source agent building platform.
----------------------
SPEC.MD
----------------------
# RFC Specification for Simple Language Open Protocol (SLOP)
Version: 1.0.0
Status: Draft
Date: 2025-03-08

## Abstract

This document specifies the Simple Language Open Protocol (SLOP), a minimal HTTP-based protocol for AI agent interoperability. There are exactly five core endpoints with standard request/response formats. Nothing more. The spec is intentionally minimal to maximize adoption and implementation speed while ensuring interoperability.

## 1. Introduction

### 1.1 Purpose

SLOP establishes a common "handshake" pattern for AI systems. We define only what's necessary for interoperability. Everything else is left to the implementer.

### 1.2 Design Philosophy

Three principles:

1. **Simplicity Over Complexity**: HTTP requests. JSON responses. That's it.
2. **Concrete Over Abstract**: Examples with actual code, not just theory.
3. **Zero-Cost When Unused**: Implement only what you need. No overhead.

## 2. Terminology

"MUST", "SHOULD", and other key terms follow [RFC2119](https://www.ietf.org/rfc/rfc2119.txt).

- **Agent**: System that processes requests and generates responses.
- **Endpoint**: URL path for interaction.
- **Thread**: Sequence of related messages.
- **Tool**: Function that an agent provides.
- **Resource**: Data or knowledge available to agents.

## 3. Conformance Requirements

You are SLOP-compliant if you:

1. Implement ANY ONE of the five core endpoints
2. Follow the JSON formats exactly as shown in examples
3. Return error responses as specified
4. Use standard HTTP status codes correctly

That's it. No hidden requirements.

## 4. Core Endpoints

SLOP has exactly five endpoints. Implementation must match example request/response formats precisely for the endpoints you choose to implement.

### 4.1 Chat Endpoint

#### 4.1.1 POST /chat

```
REQUEST:
POST /chat
Content-Type: application/json

{
  "messages": [
    {"role": "user", "content": "Hello world"}
  ],
  "thread_id": "thread_12345"  // Optional
}

RESPONSE:
HTTP/1.1 200 OK
Content-Type: application/json

{
  "message": {
    "role": "assistant",
    "content": "Hello! How can I help you today?"
  },
  "thread_id": "thread_12345"
}
```

#### 4.1.2 GET /chat/:id

```
REQUEST:
GET /chat/chat_123
Accept: application/json

RESPONSE:
HTTP/1.1 200 OK
Content-Type: application/json

{
  "id": "chat_123",
  "messages": [
    {"role": "user", "content": "Hello world"},
    {"role": "assistant", "content": "Hello! How can I help you today?"}
  ],
  "created_at": "2023-05-15T10:30:00Z"
}
```

#### 4.1.3 GET /chat/thread_:id

```
REQUEST:
GET /chat/thread_12345
Accept: application/json

RESPONSE:
HTTP/1.1 200 OK
Content-Type: application/json

{
  "thread_id": "thread_12345",
  "messages": [
    {
      "id": "msg_001",
      "role": "user", 
      "content": "Hello world",
      "created_at": "2023-05-15T10:30:00Z"
    },
    {
      "id": "msg_002",
      "role": "assistant", 
      "content": "Hello! How can I help you today?",
      "created_at": "2023-05-15T10:30:05Z"
    }
  ],
  "created_at": "2023-05-15T10:30:00Z"
}
```

### 4.2 Tools Endpoint

#### 4.2.1 GET /tools

```
REQUEST:
GET /tools
Accept: application/json

RESPONSE:
HTTP/1.1 200 OK
Content-Type: application/json

{
  "tools": [
    {
      "id": "calculator",
      "description": "Performs mathematical calculations",
      "parameters": {
        "expression": {
          "type": "string",
          "description": "Mathematical expression to evaluate"
        }
      }
    }
  ]
}
```

#### 4.2.2 POST /tools/:tool_id

```
REQUEST:
POST /tools/calculator
Content-Type: application/json

{
  "expression": "2 + 2"
}

RESPONSE:
HTTP/1.1 200 OK
Content-Type: application/json

{
  "result": 4
}
```

### 4.3 Memory Endpoint

#### 4.3.1 POST /memory

```
REQUEST:
POST /memory
Content-Type: application/json

{
  "key": "user_preference",
  "value": {
    "theme": "dark"
  }
}

RESPONSE:
HTTP/1.1 200 OK
Content-Type: application/json

{
  "status": "stored"
}
```

#### 4.3.2 GET /memory/:key

```
REQUEST:
GET /memory/user_preference
Accept: application/json

RESPONSE:
HTTP/1.1 200 OK
Content-Type: application/json

{
  "key": "user_preference",
  "value": {
    "theme": "dark"
  },
  "created_at": "2023-05-15T10:30:00Z"
}
```

#### 4.3.3 PUT /memory/:key

```
REQUEST:
PUT /memory/user_preference
Content-Type: application/json

{
  "value": {
    "theme": "light"
  }
}

RESPONSE:
HTTP/1.1 200 OK
Content-Type: application/json

{
  "status": "updated",
  "previous_value": {
    "theme": "dark"
  }
}
```

#### 4.3.4 DELETE /memory/:key

```
REQUEST:
DELETE /memory/user_preference

RESPONSE:
HTTP/1.1 200 OK
Content-Type: application/json

{
  "status": "deleted"
}
```

### 4.4 Resources Endpoint

#### 4.4.1 GET /resources

```
REQUEST:
GET /resources
Accept: application/json

RESPONSE:
HTTP/1.1 200 OK
Content-Type: application/json

{
  "resources": [
    {
      "id": "weather-api",
      "title": "Weather API Documentation",
      "type": "document"
    }
  ]
}
```

#### 4.4.2 GET /resources/:id

```
REQUEST:
GET /resources/weather-api
Accept: application/json

RESPONSE:
HTTP/1.1 200 OK
Content-Type: application/json

{
  "id": "weather-api",
  "title": "Weather API Documentation",
  "content": "The Weather API provides current weather data...",
  "type": "document",
  "created_at": "2023-05-15T10:30:00Z"
}
```

### 4.5 Pay Endpoint

#### 4.5.1 POST /pay

```
REQUEST:
POST /pay
Content-Type: application/json

{
  "amount": 5.00,
  "currency": "USD",
  "description": "API usage"
}

RESPONSE:
HTTP/1.1 200 OK
Content-Type: application/json

{
  "transaction_id": "tx_987654",
  "status": "success",
  "created_at": "2023-05-15T10:30:00Z"
}
```

#### 4.5.2 GET /pay/:id

```
REQUEST:
GET /pay/tx_987654
Accept: application/json

RESPONSE:
HTTP/1.1 200 OK
Content-Type: application/json

{
  "transaction_id": "tx_987654",
  "amount": 5.00,
  "currency": "USD",
  "description": "API usage",
  "status": "success",
  "created_at": "2023-05-15T10:30:00Z"
}
```

## 5. Error Handling

All errors MUST use standard HTTP status codes with consistent JSON responses.

```
EXAMPLE ERROR RESPONSE:
HTTP/1.1 400 Bad Request
Content-Type: application/json

{
  "error": {
    "code": "invalid_request",
    "message": "Missing required field: messages",
    "status": 400
  }
}
```

Status codes:
- `400`: Bad request - client error
- `401`: Authentication required
- `403`: Permission denied
- `404`: Not found
- `429`: Rate limit exceeded
- `500`: Server error

## 6. Connection Types

### 6.1 HTTP/REST

Standard request/response for most operations.

### 6.2 SSE for Streaming

Append `/stream` to endpoints for Server-Sent Events streaming:

```
REQUEST:
GET /chat/stream
Accept: text/event-stream

RESPONSE:
HTTP/1.1 200 OK
Content-Type: text/event-stream

data: {"content": "Hello"}
data: {"content": " world"}
data: [DONE]
```

### 6.3 WebSockets

Append `/ws` to endpoints for WebSocket connections:

```
ws://example.com/chat/ws
```

## 7. Authentication and Security

### 7.1 Bearer Token Authentication

```
Authorization: Bearer <token>
```

### 7.2 Scope Control

```
X-SLOP-Scope: chat.read,tools.execute
```

Common scopes:
- `chat.read`: Read chat messages
- `chat.write`: Send chat messages
- `tools.*`: Access all tools
- `memory.user.*`: Full user memory access

### 7.3 Security Requirements

- HTTPS always
- Input validation against schemas
- Output sanitization
- Rate limiting

## 8. Minimal Reference Implementations

### 8.1 Node.js Example (50 lines)

```javascript
const express = require('express');
const app = express();
app.use(express.json());

// Memory storage
const memory = new Map();

// CHAT endpoint
app.post('/chat', (req, res) => {
  const message = req.body.messages?.[0]?.content || '';
  res.json({
    message: {
      role: 'assistant',
      content: `You said: ${message}`
    },
    thread_id: req.body.thread_id
  });
});

// TOOLS endpoint
app.get('/tools', (_, res) => res.json({
  tools: [{id: 'echo', description: 'Echoes input'}]
}));
app.post('/tools/:id', (req, res) => {
  if (req.params.id === 'echo') {
    return res.json({result: req.body.text});
  }
  res.status(404).json({error: {code: 'not_found'}});
});

// MEMORY endpoint
app.post('/memory', (req, res) => {
  memory.set(req.body.key, req.body.value);
  res.json({status: 'stored'});
});
app.get('/memory/:key', (req, res) => {
  res.json({value: memory.get(req.params.key)});
});

app.listen(3000);
```

### 8.2 Python Example (50 lines)

```python
from flask import Flask, request, jsonify

app = Flask(__name__)
memory = {}

@app.route('/chat', methods=['POST'])
def chat():
    data = request.json
    message = data.get('messages', [{}])[0].get('content', '')
    return jsonify({
        'message': {
            'role': 'assistant',
            'content': f'You said: {message}'
        },
        'thread_id': data.get('thread_id')
    })

@app.route('/tools', methods=['GET'])
def list_tools():
    return jsonify({'tools': [{'id': 'echo', 'description': 'Echoes input'}]})

@app.route('/tools/<tool_id>', methods=['POST'])
def use_tool(tool_id):
    if tool_id == 'echo':
        return jsonify({'result': request.json.get('text', '')})
    return jsonify({'error': {'code': 'not_found'}}), 404

@app.route('/memory', methods=['POST'])
def store_memory():
    data = request.json
    memory[data['key']] = data['value']
    return jsonify({'status': 'stored'})

@app.route('/memory/<key>', methods=['GET'])
def get_memory(key):
    return jsonify({'value': memory.get(key)})

if __name__ == '__main__':
    app.run(port=3000)
```

## 9. Integration Patterns

### 9.1 Sequential

Agent A → Agent B → Agent C, with each output feeding into the next input.

### 9.2 Parallel

Multiple agents process the same input simultaneously with results combined later.

### 9.3 Branching

A router agent directs requests to specialized agents based on content analysis.

## 10. References

- [RFC2119: Key Words](https://www.ietf.org/rfc/rfc2119.txt)
- [RFC9110: HTTP Semantics](https://www.rfc-editor.org/rfc/rfc9110.html)
- [RFC8259: JSON Format](https://www.rfc-editor.org/rfc/rfc8259.html)
- [Server-Sent Events Standard](https://html.spec.whatwg.org/multipage/server-sent-events.html)
- [RFC6455: WebSockets](https://www.rfc-editor.org/rfc/rfc6455.html)

## 11. Acknowledgments

SLOP is MIT-licensed and maintained by the community. Contributions welcome at [GitHub](https://github.com/agnt-gg/slop).

